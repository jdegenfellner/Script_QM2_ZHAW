# Introduction {#intro}

## What is statistical modeling and what do we need this for?

Typically, one simplifies the complex reality (and loses information) in order to make it better
understandable, mathematically treatable and to make predictions. 

Underlying our models, there are theories which should be [falsifiable](https://en.wikipedia.org/wiki/Falsifiability)
and testable.
For instance, I would be really surprised if I pull up my multimeter and measure the voltage (V) and
electric current (I) at a resistence (R) in a circuit and find that [Ohm's law](https://en.wikipedia.org/wiki/Ohm%27s_law) $V = IR$ is not true. 
This [**law**](https://en.wikipedia.org/wiki/Scientific_law)
can be tested over and over again and if one would find a single valid counterexample, 
the law would be falsified. It is also true that the law is probably not 100% accularate,
but an extremely good approximation of reality. Real-world measurements carry 
measurement errors and when plotting the data, one would see that the data points
might not lie exactly on a straight line. This is not a problem.

A [statistical model](https://en.wikipedia.org/wiki/Statistical_model) 
is a mathematical framework that represents the 
relationships between variables, helping us understand, infer, and
predict patterns in data. It acts as a bridge between observed data 
and the real-world processes that generated them. In health research, 
where variability and uncertainty are inherent, statistical models are 
valuable tools for making sense of complex phenomena. 
You can watch [this](https://www.youtube.com/watch?v=3d5ivs_8amQ&ab_channel=VeryNormal) as short intro.

Depending on the task at hand, we would use different models.
In any case, logical reasoning and critical thinking comes first, 
then comes the model. **It makes no sense to estimate statistical models just for the sake of it**.

**All models are wrong, but some are useful**. 
Or to quote [George Box](https://www.tandfonline.com/doi/abs/10.1080/01621459.1976.10480949):

> "Since all models are wrong the scientist cannot obtain
> a 'correct' one by excessive elaboration. On the contrary
> following William of Occam he should seek an economical
> description of natural phenomena. Just as the ability to
> devise simple but evocative models is the signature of the
> great scientist so overelaboration and overparameterization is often the mark of mediocrity."

In my opinion, statistical model is an art form: difficult and beautiful.

**One goal of this course** is to improve interpretation and limitations of statistical models.
They are not magical turning data into truth. Firstly ,the rule gargabe in, garbage out (GABA) applies.
Secondly, statistical models are based on data and their variability and have intrinsict limitations
one cannot overcome even with the most sophisticated models. This is expressed for instance 
in the so-called [bias-variance trade-off](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff).
You can't have it all.

### Explanatory vs. Predictive Models

I can recommend reading [this](https://projecteuclid.org/journals/statistical-science/volume-25/issue-3/To-Explain-or-to-Predict/10.1214/10-STS330.full) 
article by Shmueli et al. (2010) on this topic.

Statistical models serve different purposes depending on the research question. Two primary goals are **explanation** 
and **prediction**, and each requires a different approach:

**Explanatory Models** focus on understanding causal relationships. 
These models aim to uncover mechanisms and answer **"why"** 
questions. For example:
   
   - Does smoking increase the risk of lung cancer? **Yes**. (If you want to see what a large effect-size looks like, check out [this study](https://bmjopen.bmj.com/content/bmjopen/8/10/e021611.full.pdf).)
   - How large is the "effect" of smoking on lung cancer? **Large**.
   - Does pain education and graded sensorimotor relearning improve disability (a question we ask in 
   our [Resolve Swiss project](https://data.snf.ch/grants/grant/220585))?

Explanatory models are **theory-driven**, designed to test hypotheses. Here, one wants to understand the underlying
mechanisms and the relationships between variables and hence often uses (parsimonious) models that are more interpretable, 
like linear regression.

**Predictive Models** prioritize forecasting future outcomes based on patterns in the data. 
These models aim to answer **"what will happen?"** For instance:
   
   - [Gait analysis](https://www.tandfonline.com/doi/abs/10.1080/03091902.2020.1822940) using Machine Learning (ML)?
   - [Skin cancer detection](https://jamanetwork.com/journals/jamadermatology/fullarticle/2756346) using neural networks?

Predictive models are **data-driven**, often using complex algorithms to achieve high accuracy. 
Their success is measured using metrics like [Root Means Square Error](https://computersciencewiki.org/index.php/Root-mean-square_error_(RMSE)) 
(RMSE), [Area Unter the Curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#:~:text=The%20area%20under%20the%20curve,ranks%20higher%20than%20'negative') 
(AUC), or **prediction error on new, unseen data**.
Any amount of model complexity is allowed. One could for instance estimate a 
[neural network](https://en.wikipedia.org/wiki/Neural_network_(machine_learning)) ("just" another statistical model) 
with many hidden layers and neurons in order to improve prediction quality. Interpretability of the model weights is not a priority here.

While explanatory and predictive goals often complement each other, 
their differences highlight the importance of clearly defining the purpose 
of your analysis. In applied health research, explanatory models help identify 
causal mechanisms, while predictive models can guide real-world decisions by 
providing actionable forecasts. Together, they enhance both our understanding 
of phenomena and our ability to make informed decisions in complex environments.

### Individual vs. Population Prediction

Another important distinction is between **individual vs. population** prediction.
In the smoking example above, we can be very sure about the mean effects that smoking has on lung cancer.
On an individual level, it is [harder to predict the outcome](https://www.liebertpub.com/doi/10.1089/rej.2019.2298). 
Nevertheless, individual predictions will be (notably) better than random guessing. We will discuss this in greater detail.

In my optinion, we should never be afraid to test als statistical models (as honestly as possible) against reality.