[["index.html", "Quantitive Methods 2, ZHAW Chapter 1 Introduction 1.1 Books we will heavily borrow from are:", " Quantitive Methods 2, ZHAW Jürgen Degenfellner 2025-01-08 Chapter 1 Introduction This script is a continuation of the first one for Quantitative Methods 1 at ZHAW. In the first part, we learned about the basics of probability theory, descriptive statistics, Bayesian statistics, and hypothesis testing. In this script, we will dive into the basics of statistical modeling - a world of aesthetic wonder and surprises. This script is a work in progress and will be updated as we go along. Please feel free to send me suggestions for improvements or corrections. As the first one, this should be a collaborative effort and will (hopefully) never be finished as our insight grows over time. For the working setup with R, please see this and the following sections in the first script. 1.1 Books we will heavily borrow from are: (Free) Statistical Rethinking, YouTube-Playlist: Statistical Rethinking 2023 (Free) Understanding Regression Analysis: A Conditional Distribution Approach Data Analysis Using Regression and Multilevel/Hierarchical Models (Free) Doing Bayesian Data Analysis "],["intro.html", "Chapter 2 Introduction 2.1 What is statistical modeling and what do we need this for?", " Chapter 2 Introduction 2.1 What is statistical modeling and what do we need this for? Typically, one simplifies the complex reality (and loses information) in order to make it better understandable, mathematically treatable and to make predictions. Underlying our models, there are theories which should be falsifiable and testable. For instance, I would be really surprised if I pull up my multimeter and measure the voltage (V) and electric current (I) at a resistence (R) in a circuit and find that Ohm’s law \\(V = IR\\) is not true. This law can be tested over and over again and if one would find a single valid counterexample, the law would be falsified. It is also true that the law is probably not 100% accularate, but an extremely good approximation of reality. Real-world measurements carry measurement errors and when plotting the data, one would see that the data points might not lie exactly on a straight line. This is not a problem. A statistical model is a mathematical framework that represents the relationships between variables, helping us understand, infer, and predict patterns in data. It acts as a bridge between observed data and the real-world processes that generated them. In health research, where variability and uncertainty are inherent, statistical models are valuable tools for making sense of complex phenomena. You can watch this as short intro. Depending on the task at hand, we would use different models. In any case, logical reasoning and critical thinking comes first, then comes the model. It makes no sense to estimate statistical models just for the sake of it. All models are wrong, but some are useful. Or to quote George Box: “Since all models are wrong the scientist cannot obtain a ‘correct’ one by excessive elaboration. On the contrary following William of Occam he should seek an economical description of natural phenomena. Just as the ability to devise simple but evocative models is the signature of the great scientist so overelaboration and overparameterization is often the mark of mediocrity.” 2.1.1 Explanatory vs. Predictive Models I can recommend this article by Shmueli et al. (2010) on this topic. Statistical models serve different purposes depending on the research question. Two primary goals are explanation and prediction, and each requires a different approach: Explanatory Models focus on understanding causal relationships. These models aim to uncover mechanisms and answer “why” questions. For example: Does smoking increase the risk of lung cancer? Yes. (If you want to see what a large effect-size looks like, check out this study.) Does pain education and graded sensorimotor relearning improve disability (a question we ask in our Resolve Swiss project)? Explanatory models are theory-driven, designed to test hypotheses. Here, one wants to understand the underlying mechanisms and the relationships between variables and hence often uses models that are interpretable, like linear regression. Predictive Models prioritize forecasting future outcomes based on patterns in the data. These models aim to answer “what will happen?” For instance: Can we predict the likelihood of hospital readmission based on patient characteristics? What is the expected recovery time for a patient given her therapy and baseline health status? Predictive models are data-driven, often using complex algorithms to achieve high accuracy. Their success is measured using metrics like RMSE, AUC, or prediction error on new, unseen data. Any amount of model complexity is allowed. One could for instance estimate a neural network (“just” another statistical model) with many hidden layers and neurons in order to improve prediction quality. Interpretability of the model weights is not a priority here. While explanatory and predictive goals often complement each other, their differences highlight the importance of clearly defining the purpose of your analysis. In applied health research, explanatory models help identify causal mechanisms, while predictive models can guide real-world decisions by providing actionable forecasts. Together, they enhance both our understanding of phenomena and our ability to make informed decisions in complex environments. Another important distinction is between individual vs. population prediction. In the smoking example above, we can be very sure about the mean effects of smoking has on lung cancer. On an individual level, it is harder to predict the outcome. Nevertheless, individual predictions will be (notably) better than random guessing. We will discuss this in greater detail. 2.1.2 Using Statistical Models in Physiotherapy Research Physiotherapy research often involves answering diverse and complex questions, from understanding treatment effectiveness to exploring patient perceptions. Statistical models are essential tools in this field because they enable researchers to systematically analyze data, uncover patterns, and make informed decisions grounded in evidence. In evidence-based physiotherapy, statistical models support several key areas: - Evaluating Treatment Effectiveness: For instance, a randomised controlled trial (RCT) might use a statistical model to compare the effectiveness of two interventions, such as manual therapy versus exercise, for managing low back pain. - Understanding Prognostic Factors: Cohort studies use models to identify variables that predict recovery times or functional improvements in patients with musculoskeletal conditions. - Diagnosing and Validating Tests: Cross-sectional studies frequently apply statistical models to assess the diagnostic accuracy of tools like physical examination techniques or imaging modalities. - Exploring Patient Experiences: Mixed-method studies may incorporate models to quantify trends while integrating qualitative insights for deeper understanding. These models help bridge the gap between raw data and clinical practice, allowing physiotherapists to: 1. Test hypotheses (e.g., does adding manual therapy to standard care improve recovery rates?). 2. Explore relationships (e.g., is age or comorbidity a stronger predictor of delayed recovery?). 3. Make predictions (e.g., which patients are most likely to benefit from a specific intervention?). By integrating statistical models into research, physiotherapists can better interpret study results and apply them in clinical decision-making. This aligns with the principles of evidence-based practice, ensuring that interventions are both effective and tailored to individual patient needs. "],["literature.html", "Chapter 3 Literature", " Chapter 3 Literature Here is a review of existing methods. "],["methods.html", "Chapter 4 Methods 4.1 math example", " Chapter 4 Methods We describe our methods in this chapter. Math can be added in body using usual syntax like this 4.1 math example \\(p\\) is unknown but expected to be around 1/3. Standard error will be approximated \\[ SE = \\sqrt{\\frac{p(1-p)}{n}} \\approx \\sqrt{\\frac{1/3 (1 - 1/3)} {300}} = 0.027 \\] You can also use math in footnotes like this1. We will approximate standard error to 0.0272 where we mention \\(p = \\frac{a}{b}\\)↩︎ \\(p\\) is unknown but expected to be around 1/3. Standard error will be approximated \\[ SE = \\sqrt{\\frac{p(1-p)}{n}} \\approx \\sqrt{\\frac{1/3 (1 - 1/3)} {300}} = 0.027 \\]↩︎ "],["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
