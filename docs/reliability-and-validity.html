<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Reliability and Validity | Quantitative Methods 2, ZHAW</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Reliability and Validity | Quantitative Methods 2, ZHAW" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Reliability and Validity | Quantitative Methods 2, ZHAW" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Jürgen Degenfellner" />


<meta name="date" content="2025-02-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-linear-regression.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.11/grViz.js"></script>
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Quantitative Methods 2</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preamble</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#books-we-will-heavily-borrow-from-are"><i class="fa fa-check"></i><b>1.1</b> Books we will heavily borrow from are:</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#if-you-need-a-good-reason-to-buy-great-books"><i class="fa fa-check"></i><b>1.2</b> If you need a good reason to buy great books…</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#what-is-statistical-modeling-and-what-do-we-need-this-for"><i class="fa fa-check"></i><b>2.1</b> What is statistical modeling and what do we need this for?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#explanatory-vs.-predictive-models"><i class="fa fa-check"></i><b>2.1.1</b> Explanatory vs. Predictive Models</a></li>
<li class="chapter" data-level="2.1.2" data-path="intro.html"><a href="intro.html#individual-vs.-population-prediction"><i class="fa fa-check"></i><b>2.1.2</b> Individual vs. Population Prediction</a></li>
<li class="chapter" data-level="2.1.3" data-path="intro.html"><a href="intro.html#practical-use-of-statistical-models"><i class="fa fa-check"></i><b>2.1.3</b> Practical Use of Statistical Models</a></li>
<li class="chapter" data-level="2.1.4" data-path="intro.html"><a href="intro.html#start-at-the-beginning"><i class="fa fa-check"></i><b>2.1.4</b> Start at the beginning</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#a-simple-model-for-adult-body-heights-in-the-bayesian-framework"><i class="fa fa-check"></i><b>2.2</b> A (simple) model for adult body heights in the Bayesian framework</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#classical_simple_mean_model"><i class="fa fa-check"></i><b>2.3</b> Classical approach for the simplest model</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#exercises"><i class="fa fa-check"></i><b>2.4</b> Exercises</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="intro.html"><a href="intro.html#exercise1_Intro"><i class="fa fa-check"></i><b>2.4.1</b> [E] Exercise 1</a></li>
<li class="chapter" data-level="2.4.2" data-path="intro.html"><a href="intro.html#exercise2_Intro"><i class="fa fa-check"></i><b>2.4.2</b> [E] Exercise 2</a></li>
<li class="chapter" data-level="2.4.3" data-path="intro.html"><a href="intro.html#exercise3_Intro"><i class="fa fa-check"></i><b>2.4.3</b> [H] Exercise 3</a></li>
<li class="chapter" data-level="2.4.4" data-path="intro.html"><a href="intro.html#exercise4_Intro"><i class="fa fa-check"></i><b>2.4.4</b> [M] Exercise 4</a></li>
<li class="chapter" data-level="2.4.5" data-path="intro.html"><a href="intro.html#exercise5_Intro"><i class="fa fa-check"></i><b>2.4.5</b> [M] Exercise 5</a></li>
<li class="chapter" data-level="2.4.6" data-path="intro.html"><a href="intro.html#exercise6_Intro"><i class="fa fa-check"></i><b>2.4.6</b> [M] Exercise 6</a></li>
<li class="chapter" data-level="2.4.7" data-path="intro.html"><a href="intro.html#exercise7_Intro"><i class="fa fa-check"></i><b>2.4.7</b> [H] Exercise 7</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#addendum"><i class="fa fa-check"></i><b>2.5</b> Addendum</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="intro.html"><a href="intro.html#bivariate_normal"><i class="fa fa-check"></i><b>2.5.1</b> The bivariate normal distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple_lin_reg_bayes"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression in the Bayesian Framework</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model-definition"><i class="fa fa-check"></i><b>3.1.1</b> Model definition</a></li>
<li class="chapter" data-level="3.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#priors"><i class="fa fa-check"></i><b>3.1.2</b> Priors</a></li>
<li class="chapter" data-level="3.1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fit-model"><i class="fa fa-check"></i><b>3.1.3</b> Fit model</a></li>
<li class="chapter" data-level="3.1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#result"><i class="fa fa-check"></i><b>3.1.4</b> Result</a></li>
<li class="chapter" data-level="3.1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#credible-bands"><i class="fa fa-check"></i><b>3.1.5</b> Credible bands</a></li>
<li class="chapter" data-level="3.1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#summary"><i class="fa fa-check"></i><b>3.1.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-linear-regression-in-the-frequentist-framework"><i class="fa fa-check"></i><b>3.2</b> Simple Linear Regression in the Frequentist Framework</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model-definition-1"><i class="fa fa-check"></i><b>3.2.1</b> Model definition</a></li>
<li class="chapter" data-level="3.2.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fit_model_simple_lin_reg_classic"><i class="fa fa-check"></i><b>3.2.2</b> Fit the model</a></li>
<li class="chapter" data-level="3.2.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#confidence_intervals_frequentist"><i class="fa fa-check"></i><b>3.2.3</b> Confidence Intervals of coefficients (Frequentist)</a></li>
<li class="chapter" data-level="3.2.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#analysis_of_variance"><i class="fa fa-check"></i><b>3.2.4</b> ANOVA (Analysis of Variance)</a></li>
<li class="chapter" data-level="3.2.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#r2---coefficient-of-determination"><i class="fa fa-check"></i><b>3.2.5</b> <span class="math inline">\(R^2\)</span> - Coefficient of Determination</a></li>
<li class="chapter" data-level="3.2.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#check-regression-assumptions"><i class="fa fa-check"></i><b>3.2.6</b> Check regression assumptions</a></li>
<li class="chapter" data-level="3.2.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#bootstrap-fit"><i class="fa fa-check"></i><b>3.2.7</b> Bootstrap fit</a></li>
<li class="chapter" data-level="3.2.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#regression-towards-the-mean"><i class="fa fa-check"></i><b>3.2.8</b> Regression towards the mean</a></li>
<li class="chapter" data-level="3.2.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#random-x-vs.-fixed-x"><i class="fa fa-check"></i><b>3.2.9</b> Random X vs. fixed X</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercises-1"><i class="fa fa-check"></i><b>3.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise1_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.1</b> [E] Exercise 1</a></li>
<li class="chapter" data-level="3.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise2_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.2</b> [E] Exercise 2</a></li>
<li class="chapter" data-level="3.3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise3_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.3</b> [M] Exercise 3</a></li>
<li class="chapter" data-level="3.3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise4_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.4</b> [H] Exercise 4</a></li>
<li class="chapter" data-level="3.3.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise5_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.5</b> [M] Exercise 5</a></li>
<li class="chapter" data-level="3.3.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise6_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.6</b> [H] Exercise 6</a></li>
<li class="chapter" data-level="3.3.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise7_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.7</b> [M] Exercise 7</a></li>
<li class="chapter" data-level="3.3.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise8_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.8</b> [E] Exercise 8</a></li>
<li class="chapter" data-level="3.3.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise9_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.9</b> [M] Exercise 9</a></li>
<li class="chapter" data-level="3.3.10" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise10_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.10</b> [M] Exercise 10</a></li>
<li class="chapter" data-level="3.3.11" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise11_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.11</b> [E] Exercise 11</a></li>
<li class="chapter" data-level="3.3.12" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise12_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.12</b> [M] Exercise 12</a></li>
<li class="chapter" data-level="3.3.13" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise13_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.13</b> [M] Exercise 13</a></li>
<li class="chapter" data-level="3.3.14" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise14_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.14</b> [M] Exercise 14</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#elearning-1"><i class="fa fa-check"></i><b>3.4</b> eLearning 1</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#linear-regression-with-2-predictors-in-the-bayesian-framework"><i class="fa fa-check"></i><b>4.1</b> Linear Regression with 2 predictors in the Bayesian Framework</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#meaning-of-linear"><i class="fa fa-check"></i><b>4.1.1</b> Meaning of “linear”</a></li>
<li class="chapter" data-level="4.1.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adding_transformed_predictor_bayes"><i class="fa fa-check"></i><b>4.1.2</b> Adding a transformed predictor to the model</a></li>
<li class="chapter" data-level="4.1.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adding_predictor_bayes"><i class="fa fa-check"></i><b>4.1.3</b> Adding another predictor to the model</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#linear-regression-with-2-predictors-in-the-frequentist-framework"><i class="fa fa-check"></i><b>4.2</b> Linear regression with 2 predictors in the Frequentist Framework</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adding_transformed_predictor_freq"><i class="fa fa-check"></i><b>4.2.1</b> Adding a transformed predictor to the model</a></li>
<li class="chapter" data-level="4.2.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adding_predictor_freq"><i class="fa fa-check"></i><b>4.2.2</b> Adding another predictor to the model</a></li>
<li class="chapter" data-level="4.2.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#interaction_term"><i class="fa fa-check"></i><b>4.2.3</b> Interaction Term <span class="math inline">\(X_1 \times X_2\)</span></a></li>
<li class="chapter" data-level="4.2.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#interaction_plot"><i class="fa fa-check"></i><b>4.2.4</b> Using an interaction plot to see a potential interaction</a></li>
<li class="chapter" data-level="4.2.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#simpsons_paradox"><i class="fa fa-check"></i><b>4.2.5</b> Simpsons Paradox</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#throwing_variables"><i class="fa fa-check"></i><b>4.3</b> What happens when you just throw variables into multiple regression?</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#pipe"><i class="fa fa-check"></i><b>4.3.1</b> Pipe</a></li>
<li class="chapter" data-level="4.3.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#fork"><i class="fa fa-check"></i><b>4.3.2</b> Fork</a></li>
<li class="chapter" data-level="4.3.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#collider"><i class="fa fa-check"></i><b>4.3.3</b> Collider</a></li>
<li class="chapter" data-level="4.3.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#multicollinearity"><i class="fa fa-check"></i><b>4.3.4</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#more-than-2-predictors"><i class="fa fa-check"></i><b>4.4</b> More than 2 predictors</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#example_nhanes"><i class="fa fa-check"></i><b>4.4.1</b> Example in NHANES data</a></li>
<li class="chapter" data-level="4.4.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#concluding-remarks"><i class="fa fa-check"></i><b>4.4.2</b> Concluding remarks</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercises-2"><i class="fa fa-check"></i><b>4.5</b> Exercises</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise1_multiple_regression"><i class="fa fa-check"></i><b>4.5.1</b> [M] Exercise 1</a></li>
<li class="chapter" data-level="4.5.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise2_multiple_regression"><i class="fa fa-check"></i><b>4.5.2</b> [E] Exercise 2</a></li>
<li class="chapter" data-level="4.5.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise3_multiple_regression"><i class="fa fa-check"></i><b>4.5.3</b> [H] Exercise 3</a></li>
<li class="chapter" data-level="4.5.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise4_multiple_regression"><i class="fa fa-check"></i><b>4.5.4</b> [E] Exercise 4</a></li>
<li class="chapter" data-level="4.5.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise5_multiple_regression"><i class="fa fa-check"></i><b>4.5.5</b> [E] Exercise 5</a></li>
<li class="chapter" data-level="4.5.6" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise6_multiple_regression"><i class="fa fa-check"></i><b>4.5.6</b> [M] Exercise 6</a></li>
<li class="chapter" data-level="4.5.7" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise7_multiple_regression"><i class="fa fa-check"></i><b>4.5.7</b> [E] Exercise 7</a></li>
<li class="chapter" data-level="4.5.8" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise8_multiple_regression"><i class="fa fa-check"></i><b>4.5.8</b> [M] Exercise 8</a></li>
<li class="chapter" data-level="4.5.9" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise9_multiple_regression"><i class="fa fa-check"></i><b>4.5.9</b> [M] Exercise 9</a></li>
<li class="chapter" data-level="4.5.10" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise10_multiple_regression"><i class="fa fa-check"></i><b>4.5.10</b> [E] Exercise 10</a></li>
<li class="chapter" data-level="4.5.11" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise11_multiple_regression"><i class="fa fa-check"></i><b>4.5.11</b> [E] Exercise 11</a></li>
<li class="chapter" data-level="4.5.12" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise12_multiple_regression"><i class="fa fa-check"></i><b>4.5.12</b> [M] Exercise 12</a></li>
<li class="chapter" data-level="4.5.13" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise13_multiple_regression"><i class="fa fa-check"></i><b>4.5.13</b> [H] Exercise 13</a></li>
<li class="chapter" data-level="4.5.14" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise14_multiple_regression"><i class="fa fa-check"></i><b>4.5.14</b> [H] Exercise 14</a></li>
<li class="chapter" data-level="4.5.15" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise15_multiple_regression"><i class="fa fa-check"></i><b>4.5.15</b> [H] Exercise 15</a></li>
<li class="chapter" data-level="4.5.16" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise16_multiple_regression"><i class="fa fa-check"></i><b>4.5.16</b> [M] Exercise 16</a></li>
<li class="chapter" data-level="4.5.17" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise17_multiple_regression"><i class="fa fa-check"></i><b>4.5.17</b> [H] Exercise 17</a></li>
<li class="chapter" data-level="4.5.18" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise18_multiple_regression"><i class="fa fa-check"></i><b>4.5.18</b> [H] Exercise 18</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html"><i class="fa fa-check"></i><b>5</b> Reliability and Validity</a>
<ul>
<li class="chapter" data-level="5.1" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#reliability"><i class="fa fa-check"></i><b>5.1</b> Reliability</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#peter-and-marys-rom-measurements"><i class="fa fa-check"></i><b>5.1.1</b> Peter and Mary’s ROM measurements</a></li>
<li class="chapter" data-level="5.1.2" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#intraclass-correlation-coefficient-icc"><i class="fa fa-check"></i><b>5.1.2</b> Intraclass Correlation Coefficient (ICC)</a></li>
<li class="chapter" data-level="5.1.3" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#difference-between-correlation-and-icc"><i class="fa fa-check"></i><b>5.1.3</b> Difference between correlation and ICC</a></li>
<li class="chapter" data-level="5.1.4" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#standard-error-of-measurement-sem"><i class="fa fa-check"></i><b>5.1.4</b> Standard Error of Measurement (SEM)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#validity"><i class="fa fa-check"></i><b>5.2</b> Validity</a></li>
<li class="chapter" data-level="5.3" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#todos"><i class="fa fa-check"></i><b>5.3</b> TODOS</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Methods 2, ZHAW</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reliability-and-validity" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Reliability and Validity<a href="reliability-and-validity.html#reliability-and-validity" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>For this chapter we refer to the book
<a href="https://www.cambridge.org/core/books/measurement-in-medicine/8BD913A1DA0ECCBA951AC4C1F719BCC5">Measurement in Medicine</a>.</p>
<p>I invite you to read the introductory chapters 1 and 2 about concepts,
theories and models, and types of measurement.</p>
<p>In general, when conducting a measurement of any sort
(laboratory measurements, scores from questionnaires, etc.),
we want to be reasonably sure</p>
<ul>
<li>that we actually <strong>measure what we intend to measure</strong>;
(<a href="https://en.wikipedia.org/wiki/Validity_(statistics)">validity</a>;
chapter 6 in the book);</li>
<li>that the measurement does <strong>not change too much</strong> if the
underlying <strong>conditions are the same</strong>
(<a href="https://en.wikipedia.org/wiki/Reliability_(statistics)">reliability</a>;
chapter 5 in the book); and</li>
<li>that we are able to detect a <strong>change</strong> if the underlying conditions change
(<a href="https://tinyurl.com/3vdcxy49">responsiveness</a>; chapter 7 in the book); and</li>
<li>that we understand the meaning of a change in the measurement
(interpretability; chapter 8 in the book).</li>
</ul>
<p>In this <a href="https://www.youtube.com/watch?v=KuT2n1w0Ixc&amp;ab_channel=Physiotutors">video</a>,
Kai jump starts you on reliability and validity.</p>
<div id="reliability" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Reliability<a href="reliability-and-validity.html#reliability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>You can watch this <a href="https://www.youtube.com/watch?v=9HSoWaRpcys&amp;ab_channel=Physiotutors">video</a>
to get started.</p>
<p>Imagine, you measure a patient (pick your favorite measurement), for example,
the range of motion (ROM) of the shoulder.</p>
<ul>
<li>If you are interested in how
similar your measurements are in comparison to your colleagues, you are
trying to determine the so-called <strong>inter-rater reliability</strong>.</li>
<li>If you are interested in how similar your measurements are when you measure
the same patient twice, you are trying to determine the so-called
<strong>intra-rater reliability</strong>.</li>
</ul>
<p>Assuming there is a true (but unknown) underlying value (of ROM),
it is clear that measurements will not be <em>exactly</em> the same.
Possible influences (potentially) causing different results are:</p>
<ul>
<li>the measurement instrument itself (e.g., the goniometer),</li>
<li>the patient (e.g., mood/motivation),</li>
<li>the examiner (e.g., mood, influence on patient),</li>
<li>the environment (e.g., the room temperature).</li>
</ul>
<p>Note that the <strong>true score</strong> is defined in our context as the average of all measurements
if we would measure repeat it an infinite number of times.</p>
<div id="peter-and-marys-rom-measurements" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Peter and Mary’s ROM measurements<a href="reliability-and-validity.html#peter-and-marys-rom-measurements" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The data can be found <a href="http://www.clinimetrics.nl/answers-to-the-assignments-in-textbook_22_0.html">here</a>.
We randomly select 50 measurements from Peter and Mary in 50 different patients,
plot their measurements and annotate the absolutely largest one.</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="reliability-and-validity.html#cb253-1" tabindex="-1"></a><span class="fu">library</span>(pacman)</span>
<span id="cb253-2"><a href="reliability-and-validity.html#cb253-2" tabindex="-1"></a><span class="fu">p_load</span>(tidyverse, readxl)</span>
<span id="cb253-3"><a href="reliability-and-validity.html#cb253-3" tabindex="-1"></a></span>
<span id="cb253-4"><a href="reliability-and-validity.html#cb253-4" tabindex="-1"></a><span class="co"># Read file</span></span>
<span id="cb253-5"><a href="reliability-and-validity.html#cb253-5" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">&quot;https://raw.githubusercontent.com/jdegenfellner/Script_QM2_ZHAW/main/data/chapter%205_assignment%201_2_wide.xls&quot;</span></span>
<span id="cb253-6"><a href="reliability-and-validity.html#cb253-6" tabindex="-1"></a>temp_file <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">&quot;.xls&quot;</span>)</span>
<span id="cb253-7"><a href="reliability-and-validity.html#cb253-7" tabindex="-1"></a><span class="fu">download.file</span>(url, temp_file, <span class="at">mode =</span> <span class="st">&quot;wb&quot;</span>)  <span class="co"># mode=&quot;wb&quot; is important for binary files</span></span>
<span id="cb253-8"><a href="reliability-and-validity.html#cb253-8" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(temp_file)</span>
<span id="cb253-9"><a href="reliability-and-validity.html#cb253-9" tabindex="-1"></a></span>
<span id="cb253-10"><a href="reliability-and-validity.html#cb253-10" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 5
##   patcode ROMnas.Mary ROMnas.Peter ROMas.Mary ROMas.Peter
##     &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1       1          90           92         88          95
## 2       2          82           88         82          90
## 3       3          82           88         57          59
## 4       4          89           89         82          81
## 5       5          80           82         48          40
## 6       6          90           96         99          85</code></pre>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="reliability-and-validity.html#cb255-1" tabindex="-1"></a><span class="fu">dim</span>(df)</span></code></pre></div>
<pre><code>## [1] 155   5</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="reliability-and-validity.html#cb257-1" tabindex="-1"></a><span class="co"># As in the book, let&#39;s randomly select 50 patients.</span></span>
<span id="cb257-2"><a href="reliability-and-validity.html#cb257-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb257-3"><a href="reliability-and-validity.html#cb257-3" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> <span class="fu">sample_n</span>(<span class="dv">50</span>)</span>
<span id="cb257-4"><a href="reliability-and-validity.html#cb257-4" tabindex="-1"></a><span class="fu">dim</span>(df)</span></code></pre></div>
<pre><code>## [1] 50  5</code></pre>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="reliability-and-validity.html#cb259-1" tabindex="-1"></a><span class="co"># &quot;as&quot; = affected shoulder</span></span>
<span id="cb259-2"><a href="reliability-and-validity.html#cb259-2" tabindex="-1"></a><span class="co"># &quot;nas&quot; = not affected shoulder</span></span>
<span id="cb259-3"><a href="reliability-and-validity.html#cb259-3" tabindex="-1"></a></span>
<span id="cb259-4"><a href="reliability-and-validity.html#cb259-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb259-5"><a href="reliability-and-validity.html#cb259-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">diff =</span> <span class="fu">abs</span>(ROMnas.Peter <span class="sc">-</span> ROMnas.Mary))  <span class="co"># Compute absolute difference</span></span>
<span id="cb259-6"><a href="reliability-and-validity.html#cb259-6" tabindex="-1"></a></span>
<span id="cb259-7"><a href="reliability-and-validity.html#cb259-7" tabindex="-1"></a>max_diff_point <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb259-8"><a href="reliability-and-validity.html#cb259-8" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(diff <span class="sc">==</span> <span class="fu">max</span>(diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))  <span class="co"># Find the row with the max difference</span></span>
<span id="cb259-9"><a href="reliability-and-validity.html#cb259-9" tabindex="-1"></a></span>
<span id="cb259-10"><a href="reliability-and-validity.html#cb259-10" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb259-11"><a href="reliability-and-validity.html#cb259-11" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ROMnas.Peter, <span class="at">y =</span> ROMnas.Mary)) <span class="sc">+</span></span>
<span id="cb259-12"><a href="reliability-and-validity.html#cb259-12" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb259-13"><a href="reliability-and-validity.html#cb259-13" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> max_diff_point, <span class="fu">aes</span>(<span class="at">x =</span> ROMnas.Peter, <span class="at">y =</span> ROMnas.Mary), </span>
<span id="cb259-14"><a href="reliability-and-validity.html#cb259-14" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span>  <span class="co"># Highlight max difference point</span></span>
<span id="cb259-15"><a href="reliability-and-validity.html#cb259-15" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb259-16"><a href="reliability-and-validity.html#cb259-16" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb259-17"><a href="reliability-and-validity.html#cb259-17" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROMnas.Peter vs. ROMnas.Mary&quot;</span>) <span class="sc">+</span></span>
<span id="cb259-18"><a href="reliability-and-validity.html#cb259-18" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb259-19"><a href="reliability-and-validity.html#cb259-19" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x =</span> max_diff_point<span class="sc">$</span>ROMnas.Peter, </span>
<span id="cb259-20"><a href="reliability-and-validity.html#cb259-20" tabindex="-1"></a>           <span class="at">y =</span> max_diff_point<span class="sc">$</span>ROMnas.Mary, </span>
<span id="cb259-21"><a href="reliability-and-validity.html#cb259-21" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">&quot;Max Diff: &quot;</span>, <span class="fu">round</span>(max_diff_point<span class="sc">$</span>diff, <span class="dv">2</span>)), </span>
<span id="cb259-22"><a href="reliability-and-validity.html#cb259-22" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-96-1.png" width="672" /></p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="reliability-and-validity.html#cb260-1" tabindex="-1"></a><span class="co"># average abs. difference:</span></span>
<span id="cb260-2"><a href="reliability-and-validity.html#cb260-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="co"># 7.2</span></span></code></pre></div>
<pre><code>## [1] 7.2</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="reliability-and-validity.html#cb262-1" tabindex="-1"></a><span class="fu">cor</span>(df<span class="sc">$</span>ROMnas.Peter, df<span class="sc">$</span>ROMnas.Mary, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>) </span></code></pre></div>
<pre><code>## [1] 0.2403213</code></pre>
<p>The red line represents the line of equality (<span class="math inline">\(y=x\)</span>). If the measurements are
exactly the same,
all points would lie on this line. The blue point represents the largest
difference in measured Range of Motion (ROM) values between Peter and Mary
from the randomly chosen 50 people. Note that the maximum difference in
all 155 patients is 35 degrees.</p>
<p>The first simple measure of agreement we could use is the correlation, which
measures the strength and direction of a linear relationship between two variables.
But correlation does not exactly measure what we want. If there was a bias
(e.g., Mary systematically measures 5 degrees more than Peter), correlation would not
notice this. (-&gt; exercise later…). It actually is too optimistic about
the agreement since it only cares about the linearity and not about a potential bias.
<span class="math inline">\(r=0.2403213\)</span> which indicates a weak positive correlation. Higher values of Peter’s
are associated with higher values of Mary’s measurements.
But: Knowing Peter’s measurement does not help us to <em>predict</em> Mary’s measurement
at such a low correlation (-&gt; exercise later).
So, on the <em>not affected shoulder</em> (nas), the agreement is really bad.</p>
<p>What about the affected shoulder (as)?</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="reliability-and-validity.html#cb264-1" tabindex="-1"></a><span class="fu">library</span>(ggExtra)</span>
<span id="cb264-2"><a href="reliability-and-validity.html#cb264-2" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb264-3"><a href="reliability-and-validity.html#cb264-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">diff =</span> <span class="fu">abs</span>(ROMas.Peter <span class="sc">-</span> ROMas.Mary))  <span class="co"># Compute absolute difference</span></span>
<span id="cb264-4"><a href="reliability-and-validity.html#cb264-4" tabindex="-1"></a></span>
<span id="cb264-5"><a href="reliability-and-validity.html#cb264-5" tabindex="-1"></a>max_diff_point <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb264-6"><a href="reliability-and-validity.html#cb264-6" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(diff <span class="sc">==</span> <span class="fu">max</span>(diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))  <span class="co"># Find the row with the max difference</span></span>
<span id="cb264-7"><a href="reliability-and-validity.html#cb264-7" tabindex="-1"></a></span>
<span id="cb264-8"><a href="reliability-and-validity.html#cb264-8" tabindex="-1"></a>p <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb264-9"><a href="reliability-and-validity.html#cb264-9" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ROMas.Peter, <span class="at">y =</span> ROMas.Mary)) <span class="sc">+</span></span>
<span id="cb264-10"><a href="reliability-and-validity.html#cb264-10" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb264-11"><a href="reliability-and-validity.html#cb264-11" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> max_diff_point, <span class="fu">aes</span>(<span class="at">x =</span> ROMas.Peter, <span class="at">y =</span> ROMas.Mary), </span>
<span id="cb264-12"><a href="reliability-and-validity.html#cb264-12" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span>  <span class="co"># Highlight max difference point</span></span>
<span id="cb264-13"><a href="reliability-and-validity.html#cb264-13" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb264-14"><a href="reliability-and-validity.html#cb264-14" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb264-15"><a href="reliability-and-validity.html#cb264-15" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROMas.Peter vs. ROMas.Mary&quot;</span>) <span class="sc">+</span></span>
<span id="cb264-16"><a href="reliability-and-validity.html#cb264-16" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb264-17"><a href="reliability-and-validity.html#cb264-17" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x =</span> max_diff_point<span class="sc">$</span>ROMas.Peter, </span>
<span id="cb264-18"><a href="reliability-and-validity.html#cb264-18" tabindex="-1"></a>           <span class="at">y =</span> max_diff_point<span class="sc">$</span>ROMas.Mary, </span>
<span id="cb264-19"><a href="reliability-and-validity.html#cb264-19" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">&quot;Max Diff: &quot;</span>, <span class="fu">round</span>(max_diff_point<span class="sc">$</span>diff, <span class="dv">2</span>)), </span>
<span id="cb264-20"><a href="reliability-and-validity.html#cb264-20" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>)</span>
<span id="cb264-21"><a href="reliability-and-validity.html#cb264-21" tabindex="-1"></a><span class="co"># Add marginal histograms</span></span>
<span id="cb264-22"><a href="reliability-and-validity.html#cb264-22" tabindex="-1"></a><span class="fu">ggMarginal</span>(p, <span class="at">type =</span> <span class="st">&quot;density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-97-1.png" width="672" /></p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="reliability-and-validity.html#cb265-1" tabindex="-1"></a><span class="co"># average abs. difference:</span></span>
<span id="cb265-2"><a href="reliability-and-validity.html#cb265-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="co"># 7.2</span></span></code></pre></div>
<pre><code>## [1] 7.78</code></pre>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="reliability-and-validity.html#cb267-1" tabindex="-1"></a><span class="fu">cor</span>(df<span class="sc">$</span>ROMas.Peter, df<span class="sc">$</span>ROMas.Mary, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>) </span></code></pre></div>
<pre><code>## [1] 0.8516653</code></pre>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="reliability-and-validity.html#cb269-1" tabindex="-1"></a><span class="co"># mean difference</span></span>
<span id="cb269-2"><a href="reliability-and-validity.html#cb269-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>ROMas.Peter <span class="sc">-</span> df<span class="sc">$</span>ROMas.Mary, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) </span></code></pre></div>
<pre><code>## [1] 1.22</code></pre>
<p>In the affected side, the average absolute difference is even larger (<span class="math inline">\(7.78\)</span>)
with a maximum absolute difference of 37 degrees,
but the correlation is much higher (<span class="math inline">\(r=0.8516653\)</span>). See Figure 5.2 in the book.</p>
<p>Btw, this is an an example for using the correlation coefficient even though
the marginal distributions are not normal: There are much more measurements in the higher
values around 80 than below, say, 60. But the correlation coefficient makes sense
for descriptive purposes.</p>
<p>In this case, knowing Peter’s measurement <em>does</em> help us to predict
Mary’s measurement (-&gt; exercise later).</p>
</div>
<div id="intraclass-correlation-coefficient-icc" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Intraclass Correlation Coefficient (ICC)<a href="reliability-and-validity.html#intraclass-correlation-coefficient-icc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One way to measure reliability is to use the intraclass correlation coefficient (ICC).</p>
<p>This measure is based on the idea that observed score <span class="math inline">\(Y_i\)</span> consists of the true score
(ROM) and a measurement error (for each person).
The proportion of the true score variability to the total variability is the ICC.</p>
<p>In the background one thinks of a statistical model from the
<a href="https://en.wikipedia.org/wiki/Classical_test_theory">Classical Test Theory (CTT)</a>.
There is</p>
<ul>
<li>a true underlying score <span class="math inline">\(\eta_i\)</span> (for each patient i) and</li>
<li>an error term <span class="math inline">\(\varepsilon \sim N(0, \sigma_i)\)</span> which is the difference between the true
score and</li>
<li>the observed score <span class="math inline">\(Y_i\)</span>.</li>
</ul>
<p><span class="math display">\[ Y_i = \eta_i + \varepsilon_i \]</span></p>
<p>It is assumed that <span class="math inline">\(\eta_i\)</span> and <span class="math inline">\(\varepsilon_i\)</span> are independent: (<span class="math inline">\(\mathbb{C}ov(\eta_i, \varepsilon_i)=0\)</span>).
This is a nice assumption because now we know (see <a href="https://en.wikipedia.org/wiki/Variance#Addition_and_multiplication_by_a_constant">here</a>)
that the variability
of the observed score <span class="math inline">\(Y_i\)</span> is just the sum of the variability of the true score <span class="math inline">\(\eta_i\)</span>
and the variability of the error term <span class="math inline">\(\varepsilon_i\)</span>:</p>
<p><span class="math display">\[ \mathbb{V}ar(Y_i) = \mathbb{V}ar(\eta_i) + \mathbb{V}ar(\varepsilon_i) \]</span>
<span class="math display">\[ \sigma_{Y_i}^2 = \sigma_{\eta_i}^2 + \sigma_{\varepsilon_i}^2 \]</span></p>
<p>We want most of the variability in our observed scores <span class="math inline">\(Y_i\)</span> to be explained by the
true but unobservable scores <span class="math inline">\(\eta_i\)</span>. The measurement error <span class="math inline">\(\varepsilon_i\)</span> should be
be comparatively small. If it is large, we are mostly measuring noise or at least not
what we want to measure.</p>
<p>If you either pull two people with the same true but unobservable score <span class="math inline">\(\eta\)</span> out of the population
or measure the same person twice and the score does not change in between, we can
<strong>define reliability as correlation between these two measurements</strong>:</p>
<p><span class="math display">\[Y_1 = \eta + \varepsilon_1\]</span>
<span class="math display">\[Y_2 = \eta + \varepsilon_2\]</span></p>
<p><span class="math display">\[cor(Y_1, Y_2) = cor(\eta + \varepsilon_1, \eta + \varepsilon_2) =
\frac{Cov(\eta + \varepsilon_1, \eta + \varepsilon_2)}{\sigma_{Y_1}\sigma_{Y_2}}  = \]</span></p>
<p>If we use the <a href="https://en.wikipedia.org/wiki/Covariance#Properties">properties of the covariance</a>,
and the fact that the errors <span class="math inline">\(\varepsilon_1\)</span> and <span class="math inline">\(\varepsilon_2\)</span> are independent, we get:</p>
<p><span class="math display">\[ \frac{Cov(\eta, \eta) + Cov(\eta, \varepsilon_2) + Cov(\varepsilon_1, \eta) + Cov(\varepsilon_1, \varepsilon_2)}{\sigma_{Y_1} \sigma_{Y_2}}  = \]</span>
<span class="math display">\[ \frac{\sigma_{\eta}^2 + 0 + 0 + 0}{\sigma_{Y_1} \sigma_{Y_2}}\]</span></p>
<p>Since <span class="math inline">\(\eta\)</span> is a random variable (we draw a person randomly from the population),
it is well defined to talk about the variance of <span class="math inline">\(\eta\)</span> (i.e., <span class="math inline">\(\sigma_{\eta}^2\)</span>).
I think this aspect may not come across in the book quite so clearly.</p>
<p>Furthermore, it does not matter if I call the measurement <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(Y_2\)</span> or more gerneral
<span class="math inline">\(Y\)</span>, since they have the same variance and true score:</p>
<p><span class="math display">\[\sigma_{Y} = \sigma_{Y_1} = \sigma_{Y_2}\]</span></p>
<p>Hence, it follows that:</p>
<p><span class="math display">\[cor(Y_1, Y_2) =  \frac{\sigma_{\eta}^2}{\sigma_{Y}^2} = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>This is the <strong>intraclass correlation coefficient (ICC)</strong>. It is the proportion of the
true score variability to the total variability. The ICC is a number between 0 and 1 (think about why!).</p>
<p>Depending on how much deviation from the true but unknown <span class="math inline">\(\eta\)</span> we throw into the error term <span class="math inline">\(\varepsilon\)</span>,
you get different versions of the ICC. We will probably stick with the simple versions <span class="math inline">\(ICC_{agreement}\)</span>
and <span class="math inline">\(ICC_{consistency}\)</span> here and make sure we understand those.</p>
<p>Let’s look again at the term for the ICC above and divide the numerator and the denominator by
<span class="math inline">\(\sigma_{\eta}^2\)</span>, which we can do, since it is a positive number:</p>
<p><span class="math display">\[ \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2} =
\frac{1}{1 + \frac{\sigma_{\varepsilon}^2}{\sigma_{\eta}^2}}\]</span></p>
<p>We could call the term <span class="math inline">\(\frac{\sigma_{\varepsilon}^2}{\sigma_{\eta}^2}\)</span> the noise-to-signal ratio.
The higher this ratio, the lower the ICC. The lower the ratio, the higher the ICC.</p>
<ul>
<li>If you increase the noise (measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>) for fixed
true score variability <span class="math inline">\(\sigma_{\eta}^2\)</span>, the ICC decreases, because the denominator
increases.</li>
<li>If you increase the true score variability <span class="math inline">\(\sigma_{\eta}^2\)</span> for fixed noise<span class="math inline">\(\sigma_{\varepsilon}^2\)</span>,
the ICC increases, since the denominator decreases.</li>
</ul>
<p>Btw, we could also divide by <span class="math inline">\(\sigma_{\varepsilon}^2\)</span> and get the signal-to-noise ratio.</p>
<p>At first glance, the following statement seems wrong:</p>
<p>In a very <strong>homogeneous population</strong> (patients have very similar scores/measurements),
the <strong>ICC might be very low</strong>. The reason is that the patient variability <span class="math inline">\(\sigma_{\eta}^2\)</span> is low
and you probably have some measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>.
Hence, if you look at the formula, ICC must be low (for a given measurement error).</p>
<p>On the other hand, if you have a very <strong>heterogeneous population</strong> (patients have rather different
scores/measurements), the <strong>ICC might be very high</strong>.
The reason is that the patient variability <span class="math inline">\(\sigma_{\eta}^2\)</span> is high and you probably
have some measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>.</p>
<p><strong>What matters is the ratio of the two</strong>, as can be seen from the formula above.</p>
<p>Let’s try to calculate the ICC for our data using a statistical model. There are a couple of different
R packages to do this. We will use the <code>irr</code> package.</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="reliability-and-validity.html#cb271-1" tabindex="-1"></a><span class="fu">library</span>(irr)</span></code></pre></div>
<pre><code>## Loading required package: lpSolve</code></pre>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="reliability-and-validity.html#cb273-1" tabindex="-1"></a>irr<span class="sc">::</span><span class="fu">icc</span>(<span class="fu">as.matrix</span>(df[, <span class="fu">c</span>(<span class="st">&quot;ROMas.Peter&quot;</span>, <span class="st">&quot;ROMas.Mary&quot;</span>)]), </span>
<span id="cb273-2"><a href="reliability-and-validity.html#cb273-2" tabindex="-1"></a>    <span class="at">model =</span> <span class="st">&quot;oneway&quot;</span>, <span class="at">type =</span> <span class="st">&quot;consistency&quot;</span>)</span></code></pre></div>
<pre><code>##  Single Score Intraclass Correlation
## 
##    Model: oneway 
##    Type : consistency 
## 
##    Subjects = 50 
##      Raters = 2 
##      ICC(1) = 0.851
## 
##  F-Test, H0: r0 = 0 ; H1: r0 &gt; 0 
##    F(49,50) = 12.4 , p = 7.31e-16 
## 
##  95%-Confidence Interval for ICC Population Values:
##   0.753 &lt; ICC &lt; 0.913</code></pre>
<p>We get the result: <span class="math inline">\(ICC(1) = 0.851\)</span>.</p>
<p>Since we are regression model experts, we would like to see if we can get the result using the Bayesian
framework.</p>
<p>Below is the model structure. Explanation of the model:</p>
<ul>
<li><span class="math inline">\(Y_i\)</span> is the observed score (ROM) for patient <span class="math inline">\(ID\)</span>.</li>
<li><span class="math inline">\(\mu_i\)</span> is the expected value of the observed score for patient <span class="math inline">\(ID\)</span>.</li>
<li><span class="math inline">\(\sigma_{\varepsilon}\)</span> is the standard deviation of the measurement error.</li>
<li><span class="math inline">\(\alpha[ID]\)</span> is the patient-specific intercept.
Since every patient has a different intercept, and they
come from a normal distribution, we have a <strong>random intercepts model</strong>.</li>
<li><span class="math inline">\(\alpha_{mean}\)</span> is mean of the prior for the patient-specific intercepts.</li>
<li><span class="math inline">\(\sigma_{\alpha}\)</span> is the standard deviation of the patient-specific intercepts.
This is the patient variability!</li>
<li>The ICC is then calculated as
<span class="math inline">\(\frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 + \sigma_{\varepsilon}^2}\)</span>.</li>
</ul>
<p><span class="math display">\[
\begin{eqnarray*}
Y_i &amp;\sim&amp; N(\mu_i, \sigma_{\varepsilon}) \\
\mu_i &amp;=&amp; \alpha[ID] \\
\alpha[ID] &amp;\sim&amp; \text{Normal}(\alpha_{ID mean}, \sigma_{\alpha}) \\
\alpha_{IDmean} &amp;\sim&amp; \text{Normal}(66, 20) \\
\sigma_{\alpha} &amp;\sim&amp; \text{Uniform}(0,20) \\
\sigma_{\varepsilon} &amp;\sim&amp; \text{Uniform}(0,20)
\end{eqnarray*}
\]</span></p>
<p>We did not even notice it, but this was our first <strong>multilevel regression model</strong>.
It is multilevel due to the extra layer of patient-specific intercepts.
The observations are obviously clustered within patients, since observations
from the same patient are more similar than observations from different patients.</p>
<p>Draw model structure … exercise..</p>
<p>This time we fire up the <code>rethinking</code> package and use the <code>ulam</code> function
to fit the model.
This uses Markov Chain Monte Carlo (MCMC) to sample from the posterior
distribution of the parameters.
The <code>chains</code> argument specifies how many chains we want to run, and the <code>cores</code> argument
specifies how many cores we want to use.</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="reliability-and-validity.html#cb275-1" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb275-2"><a href="reliability-and-validity.html#cb275-2" tabindex="-1"></a><span class="fu">library</span>(tictoc)</span>
<span id="cb275-3"><a href="reliability-and-validity.html#cb275-3" tabindex="-1"></a></span>
<span id="cb275-4"><a href="reliability-and-validity.html#cb275-4" tabindex="-1"></a>data_ <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb275-5"><a href="reliability-and-validity.html#cb275-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="fu">row_number</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb275-6"><a href="reliability-and-validity.html#cb275-6" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(ID,ROMas.Peter, ROMas.Mary) <span class="sc">%&gt;%</span> </span>
<span id="cb275-7"><a href="reliability-and-validity.html#cb275-7" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(ROMas.Peter, ROMas.Mary), </span>
<span id="cb275-8"><a href="reliability-and-validity.html#cb275-8" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">&quot;Rater&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;ROM&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb275-9"><a href="reliability-and-validity.html#cb275-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Rater =</span> <span class="fu">factor</span>(Rater))</span>
<span id="cb275-10"><a href="reliability-and-validity.html#cb275-10" tabindex="-1"></a></span>
<span id="cb275-11"><a href="reliability-and-validity.html#cb275-11" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb275-12"><a href="reliability-and-validity.html#cb275-12" tabindex="-1"></a>m5<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb275-13"><a href="reliability-and-validity.html#cb275-13" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb275-14"><a href="reliability-and-validity.html#cb275-14" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb275-15"><a href="reliability-and-validity.html#cb275-15" tabindex="-1"></a>    ROM <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb275-16"><a href="reliability-and-validity.html#cb275-16" tabindex="-1"></a>    </span>
<span id="cb275-17"><a href="reliability-and-validity.html#cb275-17" tabindex="-1"></a>    <span class="co"># Patient-specific intercepts (random effects)</span></span>
<span id="cb275-18"><a href="reliability-and-validity.html#cb275-18" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a[ID],  </span>
<span id="cb275-19"><a href="reliability-and-validity.html#cb275-19" tabindex="-1"></a>    a[ID] <span class="sc">~</span> <span class="fu">dnorm</span>(a_bar, sigma_ID),  <span class="co"># Hierarchical structure for patients</span></span>
<span id="cb275-20"><a href="reliability-and-validity.html#cb275-20" tabindex="-1"></a>    </span>
<span id="cb275-21"><a href="reliability-and-validity.html#cb275-21" tabindex="-1"></a>    <span class="co"># Priors for hyperparameters</span></span>
<span id="cb275-22"><a href="reliability-and-validity.html#cb275-22" tabindex="-1"></a>    a_bar <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">66</span>, <span class="dv">20</span>),  <span class="co"># Population-level mean</span></span>
<span id="cb275-23"><a href="reliability-and-validity.html#cb275-23" tabindex="-1"></a>    sigma_ID <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">20</span>),  <span class="co"># Between-patient standard deviation</span></span>
<span id="cb275-24"><a href="reliability-and-validity.html#cb275-24" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">20</span>)  <span class="co"># Residual standard deviation</span></span>
<span id="cb275-25"><a href="reliability-and-validity.html#cb275-25" tabindex="-1"></a>  ), </span>
<span id="cb275-26"><a href="reliability-and-validity.html#cb275-26" tabindex="-1"></a>  <span class="at">data =</span> data_, </span>
<span id="cb275-27"><a href="reliability-and-validity.html#cb275-27" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">8</span>, <span class="at">cores =</span> <span class="dv">4</span></span>
<span id="cb275-28"><a href="reliability-and-validity.html#cb275-28" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Running MCMC with 8 chains, at most 4 in parallel, with 1 thread(s) per chain...
## 
## Chain 1 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 1 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 1 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmptNs2AQ/model-cd6d21714a3e.stan&#39;, line 17, column 4 to column 35)</code></pre>
<pre><code>## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 1</code></pre>
<pre><code>## Chain 2 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 2 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 2 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmptNs2AQ/model-cd6d21714a3e.stan&#39;, line 17, column 4 to column 35)</code></pre>
<pre><code>## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 2</code></pre>
<pre><code>## Chain 3 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 3 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 4 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 4 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 4 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 4 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmptNs2AQ/model-cd6d21714a3e.stan&#39;, line 17, column 4 to column 35)</code></pre>
<pre><code>## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 4</code></pre>
<pre><code>## Chain 1 finished in 0.1 seconds.
## Chain 2 finished in 0.2 seconds.
## Chain 3 finished in 0.1 seconds.
## Chain 4 finished in 0.1 seconds.
## Chain 5 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 5 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 5 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 5 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 5 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 5 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 5 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 5 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 5 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 5 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 5 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 5 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 5 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 5 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmptNs2AQ/model-cd6d21714a3e.stan&#39;, line 17, column 4 to column 35)</code></pre>
<pre><code>## Chain 5 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 5 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 5</code></pre>
<pre><code>## Chain 6 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 6 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 6 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 6 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 6 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 6 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 6 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 6 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 6 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 6 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 6 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 6 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 6 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 6 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/RtmptNs2AQ/model-cd6d21714a3e.stan&#39;, line 17, column 4 to column 35)</code></pre>
<pre><code>## Chain 6 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 6 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 6</code></pre>
<pre><code>## Chain 7 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 7 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 7 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 7 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 7 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 7 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 7 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 7 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 7 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 7 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 7 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 7 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 8 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 8 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 8 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 8 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 8 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 8 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 8 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 8 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 5 finished in 0.1 seconds.
## Chain 6 finished in 0.1 seconds.
## Chain 7 finished in 0.1 seconds.
## Chain 8 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 8 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 8 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 finished in 0.1 seconds.
## 
## All 8 chains finished successfully.
## Mean chain execution time: 0.1 seconds.
## Total execution time: 0.7 seconds.</code></pre>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="reliability-and-validity.html#cb307-1" tabindex="-1"></a><span class="fu">toc</span>() <span class="co"># 7s</span></span></code></pre></div>
<pre><code>## 7.282 sec elapsed</code></pre>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="reliability-and-validity.html#cb309-1" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.1</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##               mean        sd      5.5%     94.5%      rhat ess_bulk
## a[1]     67.722244 4.9090800 59.884240 75.424230 1.0011883 6619.262
## a[2]     64.111654 4.7840605 56.528447 71.776798 1.0034783 6191.276
## a[3]     86.987105 4.8248501 79.310842 94.721499 1.0021836 6533.691
## a[4]     76.488312 4.8772869 68.688592 84.377506 1.0004241 6088.506
## a[5]     58.652587 4.9146668 50.800481 66.376233 1.0057245 6894.371
## a[6]     69.286318 4.9001887 61.446915 77.135439 1.0023860 6440.228
## a[7]     69.630175 4.7214488 62.093989 77.274188 1.0042853 6102.224
## a[8]     67.364715 4.8073624 59.760551 74.940179 1.0004233 6926.255
## a[9]     70.982913 4.8029119 63.473921 78.838160 1.0021779 6096.437
## a[10]    81.123297 4.6829024 73.463408 88.601603 1.0000833 5882.855
## a[11]    70.525946 4.7789205 62.916758 78.015190 1.0027020 6057.395
## a[12]    42.158971 4.9255574 34.330380 50.142874 1.0052952 5608.430
## a[13]    86.981146 4.8049263 79.173926 94.829309 1.0006401 5697.280
## a[14]    74.665706 4.6060512 67.261235 81.970150 1.0042568 6217.659
## a[15]    76.383198 4.8629608 68.375808 84.099854 1.0019507 5393.146
## a[16]    34.941636 4.9924846 27.056167 43.018477 1.0015714 6091.685
## a[17]    84.803446 4.7374711 77.144124 92.406944 0.9993908 4742.513
## a[18]    64.997487 4.9643186 56.943773 72.939016 1.0035173 6046.231
## a[19]    63.285164 4.9025730 55.533948 71.178041 1.0013061 5093.825
## a[20]    79.685208 5.0087033 71.658232 87.571054 1.0025818 5732.622
## a[21]    30.284397 4.9534314 22.471539 38.175759 1.0029669 4993.642
## a[22]    62.717165 4.8429270 55.056809 70.508550 1.0042888 5186.047
## a[23]    67.369138 4.7935870 59.691637 75.021504 1.0015468 5712.044
## a[24]    81.364895 4.6500222 73.951702 88.744605 1.0010820 5840.154
## a[25]    54.960936 4.6723859 47.304353 62.472893 1.0031483 6486.986
## a[26]    67.484558 4.8629666 59.694329 75.237344 1.0024718 5631.800
## a[27]    75.662864 4.6822039 68.289372 83.149005 1.0015293 5142.724
## a[28]    81.458669 4.7261292 73.931357 89.044628 1.0007963 6429.453
## a[29]    46.319123 4.9454046 38.515295 54.285881 1.0011816 5884.281
## a[30]    61.257367 4.7772157 53.562560 68.978274 1.0023302 5689.914
## a[31]    23.509215 4.9033830 15.777376 31.510781 1.0033955 4020.937
## a[32]    74.135907 4.9851734 66.120570 81.958539 1.0022234 6227.534
## a[33]    70.503386 4.7654367 62.891725 78.072130 1.0023102 5314.875
## a[34]    76.514259 4.7673813 69.060676 84.004384 1.0056486 6295.756
## a[35]    75.552330 4.7650873 68.063417 83.238239 1.0059815 6458.817
## a[36]    69.318470 4.8028313 61.733604 76.842796 1.0019923 5624.692
## a[37]    49.567778 4.8517137 42.000534 57.348616 1.0001428 5345.948
## a[38]    73.807516 4.8704217 66.012632 81.610347 1.0014698 5593.351
## a[39]    72.757513 4.8058223 65.331446 80.543411 0.9996477 6046.893
## a[40]    45.817525 4.8801249 38.090789 53.659197 1.0017618 5810.945
## a[41]    73.683223 4.8798317 65.754844 81.586076 0.9997154 5788.226
## a[42]    26.096569 5.0020037 18.151000 34.085055 1.0035820 5645.769
## a[43]    32.929828 4.9839276 25.060965 40.934064 1.0009925 4969.622
## a[44]    74.142579 4.8767249 66.482373 81.844996 1.0027673 5518.837
## a[45]    76.914062 4.8315152 69.190795 84.479135 1.0021492 5799.564
## a[46]    73.639372 4.7714194 66.006190 81.297628 1.0014867 5772.895
## a[47]    55.859204 4.8616217 48.241338 63.875677 1.0018038 5633.257
## a[48]    69.603460 4.7802544 61.990560 77.160122 1.0024286 5065.542
## a[49]    72.402414 4.6825454 65.012180 79.784921 1.0015697 5911.021
## a[50]    72.770000 4.8603442 65.014248 80.455220 1.0029222 7919.236
## a_bar    65.555333 2.4626739 61.598423 69.494927 1.0017301 4186.431
## sigma_ID 16.613184 1.6346644 14.010696 19.244560 1.0024463 1915.575
## sigma     7.081393 0.7331837  6.011486  8.331337 1.0004015 2066.538</code></pre>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="reliability-and-validity.html#cb311-1" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.1</span>)</span>
<span id="cb311-2"><a href="reliability-and-validity.html#cb311-2" tabindex="-1"></a>var_patients <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_ID<span class="sc">^</span><span class="dv">2</span>)  <span class="co"># Between-patient variance</span></span>
<span id="cb311-3"><a href="reliability-and-validity.html#cb311-3" tabindex="-1"></a>var_residual <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span>)     <span class="co"># Residual variance</span></span>
<span id="cb311-4"><a href="reliability-and-validity.html#cb311-4" tabindex="-1"></a>var_patients <span class="sc">/</span> (var_patients <span class="sc">+</span> var_residual) <span class="co"># ICC</span></span></code></pre></div>
<pre><code>## [1] 0.8461117</code></pre>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="reliability-and-validity.html#cb313-1" tabindex="-1"></a><span class="co"># 0.846</span></span>
<span id="cb313-2"><a href="reliability-and-validity.html#cb313-2" tabindex="-1"></a><span class="co"># not too bad; very close to the result from the irr package</span></span></code></pre></div>
<p>The trick to do these calculations by “hand” is to get the
variance decomposition correct.
We stumbled upon variance decomposition in the context of ANOVA,
where we decomposed the total variance into the regression variance
and the residual variance. Here, we decompose the total variance
into the between-patient variance and the residual variance.</p>
<p>We can also estimate a random intercept model with the <code>lme4</code> package using
the command <code>lmer</code>in the Frequentist framework. No priors.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="reliability-and-validity.html#cb314-1" tabindex="-1"></a><span class="fu">library</span>(lme4)</span></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="reliability-and-validity.html#cb318-1" tabindex="-1"></a>m5<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lmer</span>(ROM <span class="sc">~</span> (<span class="dv">1</span><span class="sc">|</span>ID), <span class="at">data =</span> data_)</span>
<span id="cb318-2"><a href="reliability-and-validity.html#cb318-2" tabindex="-1"></a><span class="fu">summary</span>(m5<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: ROM ~ (1 | ID)
##    Data: data_
## 
## REML criterion at convergence: 791
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.91875 -0.44821  0.00964  0.51325  1.47941 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  ID       (Intercept) 270.99   16.462  
##  Residual              47.35    6.881  
## Number of obs: 100, groups:  ID, 50
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   65.590      2.428   27.02</code></pre>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="reliability-and-validity.html#cb320-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">VarCorr</span>(m5<span class="fl">.2</span>), <span class="at">comp =</span> <span class="st">&quot;Variance&quot;</span>)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance
##  ID       (Intercept) 270.99  
##  Residual              47.35</code></pre>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="reliability-and-validity.html#cb322-1" tabindex="-1"></a><span class="co"># ICC = </span></span>
<span id="cb322-2"><a href="reliability-and-validity.html#cb322-2" tabindex="-1"></a><span class="fl">270.99</span> <span class="sc">/</span> (<span class="fl">270.99</span> <span class="sc">+</span> <span class="fl">47.35</span>) <span class="co"># </span></span></code></pre></div>
<pre><code>## [1] 0.8512597</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="reliability-and-validity.html#cb324-1" tabindex="-1"></a><span class="co"># 0.8512597</span></span>
<span id="cb324-2"><a href="reliability-and-validity.html#cb324-2" tabindex="-1"></a><span class="co"># -&gt; exactly the same result as the irr package</span></span></code></pre></div>
<p>So far, we have only looked at the <strong><span class="math inline">\(ICC_{consistency}\)</span></strong> (see also page 106 in the book).
There, we have not yet explicitely considered a bias (=systematic difference
between the raters) that the raters could introduce. In the book,
they introduce a bias of 5 degrees (Mary measures 5 degrees more than Peter on average).</p>
<p>There is also the <strong><span class="math inline">\(ICC_{agreement}\)</span></strong>, which explicitely considers this difference
that could occur between the raters.</p>
<p>We will now introduce the 5 degree bias and use our Bayesian
framework to estimate the ICC. By introducing the bias, we should see
a lower ICC (agreement). Note, that the prediction quality of Mary’s scores
given Peter’s scores should not change, since we would only shift Mary’s scores
down by 5 degrees, which would not disturb the linear regression model. We can
always move around the points to where we want them to be. We do that for instance
when we scale or standardize the data.</p>
<p>Anyhow, let’s try to give the model equations for the new model considering
the introduced bias:</p>
<p><span class="math display">\[
\begin{eqnarray*}
Y_i &amp;\sim&amp; N(\mu_i, \sigma_{\varepsilon}) \\
\mu_i &amp;=&amp; \alpha[ID] + \beta[Rater] \\
\alpha[ID] &amp;\sim&amp; \text{Normal}(\alpha_{IDmean}, \sigma_{\alpha}) \\
\beta[Rater] &amp;\sim&amp; \text{Normal}(0, \sigma_{\beta}) \\
\alpha_{IDmean} &amp;\sim&amp; \text{Normal}(66, 20) \\
\sigma_{\alpha} &amp;\sim&amp; \text{Uniform}(0,20) \\
\sigma_{\beta} &amp;\sim&amp; \text{Uniform}(0,10) \\
\sigma_{\varepsilon} &amp;\sim&amp; \text{Uniform}(0,20)
\end{eqnarray*}
\]</span></p>
<p>…</p>
</div>
<div id="difference-between-correlation-and-icc" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Difference between correlation and ICC<a href="reliability-and-validity.html#difference-between-correlation-and-icc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we do not introduce a bias in the data, the correlation coefficient
is the same as the ICC (as seen above). On page 110, Figure 5.3, they show nicely
what the difference is between the correlation coefficient and the ICC. We note:</p>
<ul>
<li>The ICC (agreement) measures how tightly the two measurements are
clustered around the line of equality (<span class="math inline">\(y=x\)</span>)……..
……..</li>
</ul>
</div>
<div id="standard-error-of-measurement-sem" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Standard Error of Measurement (SEM)<a href="reliability-and-validity.html#standard-error-of-measurement-sem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>…</p>
</div>
</div>
<div id="validity" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Validity<a href="reliability-and-validity.html#validity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>…</p>
</div>
<div id="todos" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> TODOS<a href="reliability-and-validity.html#todos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>mention missing values, missingness mechanisms -&gt; Methodenvertiefung</li>
<li>Logistic Regression, Poisson, -&gt; Methodenvertiefung</li>
<li>Exercise: Show by simulation what Gelman talks about with significant p values. So I scan the data
for significant p values and then simulate data with the same effect size and see how often
I get significant p values. Especially the next effect would be probably smaller,
especially, if one did p-hacking! Calculate a priori probability for replication (def?).</li>
<li>Chapter: Sample size calculations for multivariate regression, Proportions, ICCs, t.test</li>
<li>Chapter about Reliability, Validity and ICCs (incl. simulation of what an ICC of 0.9 or so means), but maybe reduced</li>
<li>Angenommen man hat ein masking eines Effekts und der Model fit ist aber gut (keine Voraussetzung verletzt),
ist diese Situation möglich?</li>
<li>What about papers? -&gt; eLearning</li>
<li>AIC, BIC, cross-validation, Model selection (best subset, leaps….), Variable selection</li>
<li>More on bias variance tradeoff, show for polynomial regression?</li>
<li>include eLearning tasks in script.</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-linear-regression.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-Reliability_Validity.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
