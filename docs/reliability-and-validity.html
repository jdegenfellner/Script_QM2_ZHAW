<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Reliability and Validity | Quantitative Methods 2, ZHAW</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Reliability and Validity | Quantitative Methods 2, ZHAW" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Reliability and Validity | Quantitative Methods 2, ZHAW" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Jürgen Degenfellner" />


<meta name="date" content="2025-02-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-linear-regression.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.11/grViz.js"></script>
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Quantitative Methods 2</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preamble</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#books-we-will-heavily-borrow-from-are"><i class="fa fa-check"></i><b>1.1</b> Books we will heavily borrow from are:</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#if-you-need-a-good-reason-to-buy-great-books"><i class="fa fa-check"></i><b>1.2</b> If you need a good reason to buy great books…</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#what-is-statistical-modeling-and-what-do-we-need-this-for"><i class="fa fa-check"></i><b>2.1</b> What is statistical modeling and what do we need this for?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#explanatory-vs.-predictive-models"><i class="fa fa-check"></i><b>2.1.1</b> Explanatory vs. Predictive Models</a></li>
<li class="chapter" data-level="2.1.2" data-path="intro.html"><a href="intro.html#individual-vs.-population-prediction"><i class="fa fa-check"></i><b>2.1.2</b> Individual vs. Population Prediction</a></li>
<li class="chapter" data-level="2.1.3" data-path="intro.html"><a href="intro.html#practical-use-of-statistical-models"><i class="fa fa-check"></i><b>2.1.3</b> Practical Use of Statistical Models</a></li>
<li class="chapter" data-level="2.1.4" data-path="intro.html"><a href="intro.html#start-at-the-beginning"><i class="fa fa-check"></i><b>2.1.4</b> Start at the beginning</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#a-simple-model-for-adult-body-heights-in-the-bayesian-framework"><i class="fa fa-check"></i><b>2.2</b> A (simple) model for adult body heights in the Bayesian framework</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#classical_simple_mean_model"><i class="fa fa-check"></i><b>2.3</b> Classical approach for the simplest model</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#exercises"><i class="fa fa-check"></i><b>2.4</b> Exercises</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="intro.html"><a href="intro.html#exercise1_Intro"><i class="fa fa-check"></i><b>2.4.1</b> [E] Exercise 1</a></li>
<li class="chapter" data-level="2.4.2" data-path="intro.html"><a href="intro.html#exercise2_Intro"><i class="fa fa-check"></i><b>2.4.2</b> [E] Exercise 2</a></li>
<li class="chapter" data-level="2.4.3" data-path="intro.html"><a href="intro.html#exercise3_Intro"><i class="fa fa-check"></i><b>2.4.3</b> [H] Exercise 3</a></li>
<li class="chapter" data-level="2.4.4" data-path="intro.html"><a href="intro.html#exercise4_Intro"><i class="fa fa-check"></i><b>2.4.4</b> [M] Exercise 4</a></li>
<li class="chapter" data-level="2.4.5" data-path="intro.html"><a href="intro.html#exercise5_Intro"><i class="fa fa-check"></i><b>2.4.5</b> [M] Exercise 5</a></li>
<li class="chapter" data-level="2.4.6" data-path="intro.html"><a href="intro.html#exercise6_Intro"><i class="fa fa-check"></i><b>2.4.6</b> [M] Exercise 6</a></li>
<li class="chapter" data-level="2.4.7" data-path="intro.html"><a href="intro.html#exercise7_Intro"><i class="fa fa-check"></i><b>2.4.7</b> [H] Exercise 7</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#addendum"><i class="fa fa-check"></i><b>2.5</b> Addendum</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="intro.html"><a href="intro.html#bivariate_normal"><i class="fa fa-check"></i><b>2.5.1</b> The bivariate normal distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple_lin_reg_bayes"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression in the Bayesian Framework</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model-definition"><i class="fa fa-check"></i><b>3.1.1</b> Model definition</a></li>
<li class="chapter" data-level="3.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#priors"><i class="fa fa-check"></i><b>3.1.2</b> Priors</a></li>
<li class="chapter" data-level="3.1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fit-model"><i class="fa fa-check"></i><b>3.1.3</b> Fit model</a></li>
<li class="chapter" data-level="3.1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#result"><i class="fa fa-check"></i><b>3.1.4</b> Result</a></li>
<li class="chapter" data-level="3.1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#credible-bands"><i class="fa fa-check"></i><b>3.1.5</b> Credible bands</a></li>
<li class="chapter" data-level="3.1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#summary"><i class="fa fa-check"></i><b>3.1.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-linear-regression-in-the-frequentist-framework"><i class="fa fa-check"></i><b>3.2</b> Simple Linear Regression in the Frequentist Framework</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model-definition-1"><i class="fa fa-check"></i><b>3.2.1</b> Model definition</a></li>
<li class="chapter" data-level="3.2.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fit_model_simple_lin_reg_classic"><i class="fa fa-check"></i><b>3.2.2</b> Fit the model</a></li>
<li class="chapter" data-level="3.2.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#confidence_intervals_frequentist"><i class="fa fa-check"></i><b>3.2.3</b> Confidence Intervals of coefficients (Frequentist)</a></li>
<li class="chapter" data-level="3.2.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#analysis_of_variance"><i class="fa fa-check"></i><b>3.2.4</b> ANOVA (Analysis of Variance)</a></li>
<li class="chapter" data-level="3.2.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#r2---coefficient-of-determination"><i class="fa fa-check"></i><b>3.2.5</b> <span class="math inline">\(R^2\)</span> - Coefficient of Determination</a></li>
<li class="chapter" data-level="3.2.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#check-regression-assumptions"><i class="fa fa-check"></i><b>3.2.6</b> Check regression assumptions</a></li>
<li class="chapter" data-level="3.2.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#bootstrap-fit"><i class="fa fa-check"></i><b>3.2.7</b> Bootstrap fit</a></li>
<li class="chapter" data-level="3.2.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#regression-towards-the-mean"><i class="fa fa-check"></i><b>3.2.8</b> Regression towards the mean</a></li>
<li class="chapter" data-level="3.2.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#random-x-vs.-fixed-x"><i class="fa fa-check"></i><b>3.2.9</b> Random X vs. fixed X</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercises-1"><i class="fa fa-check"></i><b>3.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise1_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.1</b> [E] Exercise 1</a></li>
<li class="chapter" data-level="3.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise2_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.2</b> [E] Exercise 2</a></li>
<li class="chapter" data-level="3.3.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise3_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.3</b> [M] Exercise 3</a></li>
<li class="chapter" data-level="3.3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise4_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.4</b> [H] Exercise 4</a></li>
<li class="chapter" data-level="3.3.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise5_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.5</b> [M] Exercise 5</a></li>
<li class="chapter" data-level="3.3.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise6_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.6</b> [H] Exercise 6</a></li>
<li class="chapter" data-level="3.3.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise7_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.7</b> [M] Exercise 7</a></li>
<li class="chapter" data-level="3.3.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise8_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.8</b> [E] Exercise 8</a></li>
<li class="chapter" data-level="3.3.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise9_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.9</b> [M] Exercise 9</a></li>
<li class="chapter" data-level="3.3.10" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise10_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.10</b> [M] Exercise 10</a></li>
<li class="chapter" data-level="3.3.11" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise11_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.11</b> [E] Exercise 11</a></li>
<li class="chapter" data-level="3.3.12" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise12_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.12</b> [M] Exercise 12</a></li>
<li class="chapter" data-level="3.3.13" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise13_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.13</b> [M] Exercise 13</a></li>
<li class="chapter" data-level="3.3.14" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercise14_simpl_lin_reg"><i class="fa fa-check"></i><b>3.3.14</b> [M] Exercise 14</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#elearning-1"><i class="fa fa-check"></i><b>3.4</b> eLearning 1</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#linear-regression-with-2-predictors-in-the-bayesian-framework"><i class="fa fa-check"></i><b>4.1</b> Linear Regression with 2 predictors in the Bayesian Framework</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#meaning-of-linear"><i class="fa fa-check"></i><b>4.1.1</b> Meaning of “linear”</a></li>
<li class="chapter" data-level="4.1.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adding_transformed_predictor_bayes"><i class="fa fa-check"></i><b>4.1.2</b> Adding a transformed predictor to the model</a></li>
<li class="chapter" data-level="4.1.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adding_predictor_bayes"><i class="fa fa-check"></i><b>4.1.3</b> Adding another predictor to the model</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#linear-regression-with-2-predictors-in-the-frequentist-framework"><i class="fa fa-check"></i><b>4.2</b> Linear regression with 2 predictors in the Frequentist Framework</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adding_transformed_predictor_freq"><i class="fa fa-check"></i><b>4.2.1</b> Adding a transformed predictor to the model</a></li>
<li class="chapter" data-level="4.2.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adding_predictor_freq"><i class="fa fa-check"></i><b>4.2.2</b> Adding another predictor to the model</a></li>
<li class="chapter" data-level="4.2.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#interaction_term"><i class="fa fa-check"></i><b>4.2.3</b> Interaction Term <span class="math inline">\(X_1 \times X_2\)</span></a></li>
<li class="chapter" data-level="4.2.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#interaction_plot"><i class="fa fa-check"></i><b>4.2.4</b> Using an interaction plot to see a potential interaction</a></li>
<li class="chapter" data-level="4.2.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#simpsons_paradox"><i class="fa fa-check"></i><b>4.2.5</b> Simpsons Paradox</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#throwing_variables"><i class="fa fa-check"></i><b>4.3</b> What happens when you just throw variables into multiple regression?</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#pipe"><i class="fa fa-check"></i><b>4.3.1</b> Pipe</a></li>
<li class="chapter" data-level="4.3.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#fork"><i class="fa fa-check"></i><b>4.3.2</b> Fork</a></li>
<li class="chapter" data-level="4.3.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#collider"><i class="fa fa-check"></i><b>4.3.3</b> Collider</a></li>
<li class="chapter" data-level="4.3.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#multicollinearity"><i class="fa fa-check"></i><b>4.3.4</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#more-than-2-predictors"><i class="fa fa-check"></i><b>4.4</b> More than 2 predictors</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#example_nhanes"><i class="fa fa-check"></i><b>4.4.1</b> Example in NHANES data</a></li>
<li class="chapter" data-level="4.4.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#concluding-remarks"><i class="fa fa-check"></i><b>4.4.2</b> Concluding remarks</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercises-2"><i class="fa fa-check"></i><b>4.5</b> Exercises</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise1_multiple_regression"><i class="fa fa-check"></i><b>4.5.1</b> [M] Exercise 1</a></li>
<li class="chapter" data-level="4.5.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise2_multiple_regression"><i class="fa fa-check"></i><b>4.5.2</b> [E] Exercise 2</a></li>
<li class="chapter" data-level="4.5.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise3_multiple_regression"><i class="fa fa-check"></i><b>4.5.3</b> [H] Exercise 3</a></li>
<li class="chapter" data-level="4.5.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise4_multiple_regression"><i class="fa fa-check"></i><b>4.5.4</b> [E] Exercise 4</a></li>
<li class="chapter" data-level="4.5.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise5_multiple_regression"><i class="fa fa-check"></i><b>4.5.5</b> [E] Exercise 5</a></li>
<li class="chapter" data-level="4.5.6" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise6_multiple_regression"><i class="fa fa-check"></i><b>4.5.6</b> [M] Exercise 6</a></li>
<li class="chapter" data-level="4.5.7" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise7_multiple_regression"><i class="fa fa-check"></i><b>4.5.7</b> [E] Exercise 7</a></li>
<li class="chapter" data-level="4.5.8" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise8_multiple_regression"><i class="fa fa-check"></i><b>4.5.8</b> [M] Exercise 8</a></li>
<li class="chapter" data-level="4.5.9" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise9_multiple_regression"><i class="fa fa-check"></i><b>4.5.9</b> [M] Exercise 9</a></li>
<li class="chapter" data-level="4.5.10" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise10_multiple_regression"><i class="fa fa-check"></i><b>4.5.10</b> [E] Exercise 10</a></li>
<li class="chapter" data-level="4.5.11" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise11_multiple_regression"><i class="fa fa-check"></i><b>4.5.11</b> [E] Exercise 11</a></li>
<li class="chapter" data-level="4.5.12" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise12_multiple_regression"><i class="fa fa-check"></i><b>4.5.12</b> [M] Exercise 12</a></li>
<li class="chapter" data-level="4.5.13" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise13_multiple_regression"><i class="fa fa-check"></i><b>4.5.13</b> [H] Exercise 13</a></li>
<li class="chapter" data-level="4.5.14" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise14_multiple_regression"><i class="fa fa-check"></i><b>4.5.14</b> [H] Exercise 14</a></li>
<li class="chapter" data-level="4.5.15" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise15_multiple_regression"><i class="fa fa-check"></i><b>4.5.15</b> [H] Exercise 15</a></li>
<li class="chapter" data-level="4.5.16" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise16_multiple_regression"><i class="fa fa-check"></i><b>4.5.16</b> [M] Exercise 16</a></li>
<li class="chapter" data-level="4.5.17" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise17_multiple_regression"><i class="fa fa-check"></i><b>4.5.17</b> [H] Exercise 17</a></li>
<li class="chapter" data-level="4.5.18" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#exercise18_multiple_regression"><i class="fa fa-check"></i><b>4.5.18</b> [H] Exercise 18</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html"><i class="fa fa-check"></i><b>5</b> Reliability and Validity</a>
<ul>
<li class="chapter" data-level="5.1" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#reliability"><i class="fa fa-check"></i><b>5.1</b> Reliability</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#peter-and-marys-rom-measurements"><i class="fa fa-check"></i><b>5.1.1</b> Peter and Mary’s ROM measurements</a></li>
<li class="chapter" data-level="5.1.2" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#intraclass-correlation-coefficient-icc"><i class="fa fa-check"></i><b>5.1.2</b> Intraclass Correlation Coefficient (ICC)</a></li>
<li class="chapter" data-level="5.1.3" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#explanation-of-iccs-in-the-psych-output"><i class="fa fa-check"></i><b>5.1.3</b> Explanation of ICCs in the <code>psych</code> output</a></li>
<li class="chapter" data-level="5.1.4" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#summary-peter-and-mary-with-and-without-bias"><i class="fa fa-check"></i><b>5.1.4</b> Summary Peter and Mary, with and without bias</a></li>
<li class="chapter" data-level="5.1.5" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#difference-between-correlation-and-icc"><i class="fa fa-check"></i><b>5.1.5</b> Difference between correlation and ICC</a></li>
<li class="chapter" data-level="5.1.6" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#bad-news-about-the-icc"><i class="fa fa-check"></i><b>5.1.6</b> Bad news about the ICC?</a></li>
<li class="chapter" data-level="5.1.7" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#standard-error-of-measurement-sem"><i class="fa fa-check"></i><b>5.1.7</b> Standard Error of Measurement (SEM)</a></li>
<li class="chapter" data-level="5.1.8" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#bland-altman-plot"><i class="fa fa-check"></i><b>5.1.8</b> Bland-Altman Plot</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#validity"><i class="fa fa-check"></i><b>5.2</b> Validity</a></li>
<li class="chapter" data-level="5.3" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#todos"><i class="fa fa-check"></i><b>5.3</b> TODOS</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Methods 2, ZHAW</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reliability-and-validity" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Reliability and Validity<a href="reliability-and-validity.html#reliability-and-validity" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>For this chapter we refer to the book
<a href="https://www.cambridge.org/core/books/measurement-in-medicine/8BD913A1DA0ECCBA951AC4C1F719BCC5">Measurement in Medicine</a>.</p>
<p>I invite you to read the introductory chapters 1 and 2 about concepts,
theories and models, and types of measurement.</p>
<p>In general, when conducting a measurement of any sort
(laboratory measurements, scores from questionnaires, etc.),
we want to be reasonably sure</p>
<ul>
<li>that we actually <strong>measure what we intend to measure</strong>;
(<a href="https://en.wikipedia.org/wiki/Validity_(statistics)">validity</a>;
chapter 6 in the book);</li>
<li>that the measurement does <strong>not change too much</strong> if the
underlying <strong>conditions are the same</strong>
(<a href="https://en.wikipedia.org/wiki/Reliability_(statistics)">reliability</a>;
chapter 5 in the book); and</li>
<li>that we are able to detect a <strong>change</strong> if the underlying conditions change
(<a href="https://tinyurl.com/3vdcxy49">responsiveness</a>; chapter 7 in the book); and</li>
<li>that we understand the meaning of a change in the measurement
(interpretability; chapter 8 in the book).</li>
</ul>
<p>In this <a href="https://www.youtube.com/watch?v=KuT2n1w0Ixc&amp;ab_channel=Physiotutors">video</a>,
Kai jump starts you on reliability and validity.</p>
<div id="reliability" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Reliability<a href="reliability-and-validity.html#reliability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>You can watch this <a href="https://www.youtube.com/watch?v=9HSoWaRpcys&amp;ab_channel=Physiotutors">video</a>
to get started.</p>
<p>Imagine, you measure a patient (pick your favorite measurement), for example,
the range of motion (ROM) of the shoulder.</p>
<ul>
<li>If you are interested in how
similar your measurements are in comparison to your colleagues, you are
trying to determine the so-called <strong>inter-rater reliability</strong>.</li>
<li>If you are interested in how similar your measurements are when you measure
the same patient twice, you are trying to determine the so-called
<strong>intra-rater reliability</strong>.</li>
</ul>
<p>Assuming there is a true (but unknown) underlying value (of ROM),
it is clear that measurements will not be <em>exactly</em> the same.
Possible influences (potentially) causing different results are:</p>
<ul>
<li>the measurement instrument itself (e.g., the goniometer),</li>
<li>the patient (e.g., mood/motivation),</li>
<li>the examiner (e.g., mood, influence on patient),</li>
<li>the environment (e.g., the room temperature).</li>
</ul>
<p>Note that the <strong>true score</strong> is defined in our context as the average of all measurements
if we would measure repeat it an infinite number of times.</p>
<div id="peter-and-marys-rom-measurements" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Peter and Mary’s ROM measurements<a href="reliability-and-validity.html#peter-and-marys-rom-measurements" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The data can be found <a href="http://www.clinimetrics.nl/answers-to-the-assignments-in-textbook_22_0.html">here</a>.
We randomly select 50 measurements from Peter and Mary in 50 different patients,
plot their measurements and annotate the absolutely largest one.</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="reliability-and-validity.html#cb253-1" tabindex="-1"></a><span class="fu">library</span>(pacman)</span>
<span id="cb253-2"><a href="reliability-and-validity.html#cb253-2" tabindex="-1"></a><span class="fu">p_load</span>(tidyverse, readxl)</span>
<span id="cb253-3"><a href="reliability-and-validity.html#cb253-3" tabindex="-1"></a></span>
<span id="cb253-4"><a href="reliability-and-validity.html#cb253-4" tabindex="-1"></a><span class="co"># Read file</span></span>
<span id="cb253-5"><a href="reliability-and-validity.html#cb253-5" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">&quot;https://raw.githubusercontent.com/jdegenfellner/Script_QM2_ZHAW/main/data/chapter%205_assignment%201_2_wide.xls&quot;</span></span>
<span id="cb253-6"><a href="reliability-and-validity.html#cb253-6" tabindex="-1"></a>temp_file <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">&quot;.xls&quot;</span>)</span>
<span id="cb253-7"><a href="reliability-and-validity.html#cb253-7" tabindex="-1"></a><span class="fu">download.file</span>(url, temp_file, <span class="at">mode =</span> <span class="st">&quot;wb&quot;</span>)  <span class="co"># mode=&quot;wb&quot; is important for binary files</span></span>
<span id="cb253-8"><a href="reliability-and-validity.html#cb253-8" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(temp_file)</span>
<span id="cb253-9"><a href="reliability-and-validity.html#cb253-9" tabindex="-1"></a></span>
<span id="cb253-10"><a href="reliability-and-validity.html#cb253-10" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 5
##   patcode ROMnas.Mary ROMnas.Peter ROMas.Mary ROMas.Peter
##     &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1       1          90           92         88          95
## 2       2          82           88         82          90
## 3       3          82           88         57          59
## 4       4          89           89         82          81
## 5       5          80           82         48          40
## 6       6          90           96         99          85</code></pre>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="reliability-and-validity.html#cb255-1" tabindex="-1"></a><span class="fu">dim</span>(df)</span></code></pre></div>
<pre><code>## [1] 155   5</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="reliability-and-validity.html#cb257-1" tabindex="-1"></a><span class="co"># As in the book, let&#39;s randomly select 50 patients.</span></span>
<span id="cb257-2"><a href="reliability-and-validity.html#cb257-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb257-3"><a href="reliability-and-validity.html#cb257-3" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> <span class="fu">sample_n</span>(<span class="dv">50</span>)</span>
<span id="cb257-4"><a href="reliability-and-validity.html#cb257-4" tabindex="-1"></a><span class="fu">dim</span>(df)</span></code></pre></div>
<pre><code>## [1] 50  5</code></pre>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="reliability-and-validity.html#cb259-1" tabindex="-1"></a><span class="co"># &quot;as&quot; = affected shoulder</span></span>
<span id="cb259-2"><a href="reliability-and-validity.html#cb259-2" tabindex="-1"></a><span class="co"># &quot;nas&quot; = not affected shoulder</span></span>
<span id="cb259-3"><a href="reliability-and-validity.html#cb259-3" tabindex="-1"></a></span>
<span id="cb259-4"><a href="reliability-and-validity.html#cb259-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb259-5"><a href="reliability-and-validity.html#cb259-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">diff =</span> <span class="fu">abs</span>(ROMnas.Peter <span class="sc">-</span> ROMnas.Mary))  <span class="co"># Compute absolute difference</span></span>
<span id="cb259-6"><a href="reliability-and-validity.html#cb259-6" tabindex="-1"></a></span>
<span id="cb259-7"><a href="reliability-and-validity.html#cb259-7" tabindex="-1"></a>max_diff_point <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb259-8"><a href="reliability-and-validity.html#cb259-8" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(diff <span class="sc">==</span> <span class="fu">max</span>(diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))  <span class="co"># Find the row with the max difference</span></span>
<span id="cb259-9"><a href="reliability-and-validity.html#cb259-9" tabindex="-1"></a></span>
<span id="cb259-10"><a href="reliability-and-validity.html#cb259-10" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb259-11"><a href="reliability-and-validity.html#cb259-11" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ROMnas.Peter, <span class="at">y =</span> ROMnas.Mary)) <span class="sc">+</span></span>
<span id="cb259-12"><a href="reliability-and-validity.html#cb259-12" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb259-13"><a href="reliability-and-validity.html#cb259-13" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> max_diff_point, <span class="fu">aes</span>(<span class="at">x =</span> ROMnas.Peter, <span class="at">y =</span> ROMnas.Mary), </span>
<span id="cb259-14"><a href="reliability-and-validity.html#cb259-14" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span>  <span class="co"># Highlight max difference point</span></span>
<span id="cb259-15"><a href="reliability-and-validity.html#cb259-15" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb259-16"><a href="reliability-and-validity.html#cb259-16" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb259-17"><a href="reliability-and-validity.html#cb259-17" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROMnas.Peter vs. ROMnas.Mary&quot;</span>) <span class="sc">+</span></span>
<span id="cb259-18"><a href="reliability-and-validity.html#cb259-18" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb259-19"><a href="reliability-and-validity.html#cb259-19" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x =</span> max_diff_point<span class="sc">$</span>ROMnas.Peter, </span>
<span id="cb259-20"><a href="reliability-and-validity.html#cb259-20" tabindex="-1"></a>           <span class="at">y =</span> max_diff_point<span class="sc">$</span>ROMnas.Mary, </span>
<span id="cb259-21"><a href="reliability-and-validity.html#cb259-21" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">&quot;Max Diff: &quot;</span>, <span class="fu">round</span>(max_diff_point<span class="sc">$</span>diff, <span class="dv">2</span>)), </span>
<span id="cb259-22"><a href="reliability-and-validity.html#cb259-22" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-96-1.png" width="672" /></p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="reliability-and-validity.html#cb260-1" tabindex="-1"></a><span class="co"># average abs. difference:</span></span>
<span id="cb260-2"><a href="reliability-and-validity.html#cb260-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="co"># 7.2</span></span></code></pre></div>
<pre><code>## [1] 7.2</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="reliability-and-validity.html#cb262-1" tabindex="-1"></a><span class="fu">cor</span>(df<span class="sc">$</span>ROMnas.Peter, df<span class="sc">$</span>ROMnas.Mary, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>) </span></code></pre></div>
<pre><code>## [1] 0.2403213</code></pre>
<p>The red line represents the line of equality (<span class="math inline">\(y=x\)</span>). If the measurements are
exactly the same,
all points would lie on this line. The blue point represents the largest
difference in measured Range of Motion (ROM) values between Peter and Mary
from the randomly chosen 50 people. Note that the maximum difference in
all 155 patients is 35 degrees.</p>
<p>The first simple measure of agreement we could use is the correlation, which
measures the strength and direction of a linear relationship between two variables.
But correlation does not exactly measure what we want. If there was a bias
(e.g., Mary systematically measures 5 degrees more than Peter), correlation would not
notice this. (-&gt; exercise later…). It actually is too optimistic about
the agreement since it only cares about the linearity and not about a potential bias.
<span class="math inline">\(r=0.2403213\)</span> which indicates a weak positive correlation. Higher values of Peter’s
are associated with higher values of Mary’s measurements.
But: Knowing Peter’s measurement does not help us to <em>predict</em> Mary’s measurement
at such a low correlation (-&gt; exercise later).
So, on the <em>not affected shoulder</em> (nas), the agreement is really bad.</p>
<p>What about the affected shoulder (as)?</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="reliability-and-validity.html#cb264-1" tabindex="-1"></a><span class="fu">library</span>(ggExtra)</span>
<span id="cb264-2"><a href="reliability-and-validity.html#cb264-2" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb264-3"><a href="reliability-and-validity.html#cb264-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">diff =</span> <span class="fu">abs</span>(ROMas.Peter <span class="sc">-</span> ROMas.Mary))  <span class="co"># Compute absolute difference</span></span>
<span id="cb264-4"><a href="reliability-and-validity.html#cb264-4" tabindex="-1"></a></span>
<span id="cb264-5"><a href="reliability-and-validity.html#cb264-5" tabindex="-1"></a>max_diff_point <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb264-6"><a href="reliability-and-validity.html#cb264-6" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(diff <span class="sc">==</span> <span class="fu">max</span>(diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))  <span class="co"># Find the row with the max difference</span></span>
<span id="cb264-7"><a href="reliability-and-validity.html#cb264-7" tabindex="-1"></a></span>
<span id="cb264-8"><a href="reliability-and-validity.html#cb264-8" tabindex="-1"></a>p <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb264-9"><a href="reliability-and-validity.html#cb264-9" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> ROMas.Peter, <span class="at">y =</span> ROMas.Mary)) <span class="sc">+</span></span>
<span id="cb264-10"><a href="reliability-and-validity.html#cb264-10" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb264-11"><a href="reliability-and-validity.html#cb264-11" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> max_diff_point, <span class="fu">aes</span>(<span class="at">x =</span> ROMas.Peter, <span class="at">y =</span> ROMas.Mary), </span>
<span id="cb264-12"><a href="reliability-and-validity.html#cb264-12" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span>  <span class="co"># Highlight max difference point</span></span>
<span id="cb264-13"><a href="reliability-and-validity.html#cb264-13" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb264-14"><a href="reliability-and-validity.html#cb264-14" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb264-15"><a href="reliability-and-validity.html#cb264-15" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROMas.Peter vs. ROMas.Mary&quot;</span>) <span class="sc">+</span></span>
<span id="cb264-16"><a href="reliability-and-validity.html#cb264-16" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb264-17"><a href="reliability-and-validity.html#cb264-17" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x =</span> max_diff_point<span class="sc">$</span>ROMas.Peter, </span>
<span id="cb264-18"><a href="reliability-and-validity.html#cb264-18" tabindex="-1"></a>           <span class="at">y =</span> max_diff_point<span class="sc">$</span>ROMas.Mary, </span>
<span id="cb264-19"><a href="reliability-and-validity.html#cb264-19" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">&quot;Max Diff: &quot;</span>, <span class="fu">round</span>(max_diff_point<span class="sc">$</span>diff, <span class="dv">2</span>)), </span>
<span id="cb264-20"><a href="reliability-and-validity.html#cb264-20" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>)</span>
<span id="cb264-21"><a href="reliability-and-validity.html#cb264-21" tabindex="-1"></a><span class="co"># Add marginal histograms</span></span>
<span id="cb264-22"><a href="reliability-and-validity.html#cb264-22" tabindex="-1"></a><span class="fu">ggMarginal</span>(p, <span class="at">type =</span> <span class="st">&quot;density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-97-1.png" width="672" /></p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="reliability-and-validity.html#cb265-1" tabindex="-1"></a><span class="co"># average abs. difference:</span></span>
<span id="cb265-2"><a href="reliability-and-validity.html#cb265-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>diff, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="co"># 7.2</span></span></code></pre></div>
<pre><code>## [1] 7.78</code></pre>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="reliability-and-validity.html#cb267-1" tabindex="-1"></a><span class="fu">cor</span>(df<span class="sc">$</span>ROMas.Peter, df<span class="sc">$</span>ROMas.Mary, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>) </span></code></pre></div>
<pre><code>## [1] 0.8516653</code></pre>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="reliability-and-validity.html#cb269-1" tabindex="-1"></a><span class="co"># mean difference</span></span>
<span id="cb269-2"><a href="reliability-and-validity.html#cb269-2" tabindex="-1"></a><span class="fu">mean</span>(df<span class="sc">$</span>ROMas.Peter <span class="sc">-</span> df<span class="sc">$</span>ROMas.Mary, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) </span></code></pre></div>
<pre><code>## [1] 1.22</code></pre>
<p>In the affected side, the average absolute difference is even larger (<span class="math inline">\(7.78\)</span>)
with a maximum absolute difference of 37 degrees,
but the correlation is much higher (<span class="math inline">\(r=0.8516653\)</span>). See Figure 5.2 in the book.</p>
<p>Btw, this is an an example for using the correlation coefficient even though
the marginal distributions are not normal: There are much more measurements in the higher
values around 80 than below, say, 60. But the correlation coefficient makes sense
for descriptive purposes.</p>
<p>In this case, knowing Peter’s measurement <em>does</em> help us to predict
Mary’s measurement (-&gt; exercise later).</p>
</div>
<div id="intraclass-correlation-coefficient-icc" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Intraclass Correlation Coefficient (ICC)<a href="reliability-and-validity.html#intraclass-correlation-coefficient-icc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One way to measure reliability is to use the intraclass correlation coefficient (ICC).</p>
<p>This measure is based on the idea that observed score <span class="math inline">\(Y_i\)</span> consists of the true score
(ROM) and a measurement error (for each person).
The proportion of the true score variability to the total variability is the ICC.</p>
<p>In the background one thinks of a statistical model from the
<a href="https://en.wikipedia.org/wiki/Classical_test_theory">Classical Test Theory (CTT)</a>.
There is</p>
<ul>
<li>a true underlying score <span class="math inline">\(\eta_i\)</span> (for each patient i) and</li>
<li>an error term <span class="math inline">\(\varepsilon_i \sim N(0, \sigma_i)\)</span> which is the difference between the true
score and</li>
<li>the observed score <span class="math inline">\(Y_i\)</span>.</li>
</ul>
<p><span class="math display">\[ Y_i = \eta_i + \varepsilon_i \]</span></p>
<p>It is assumed that <span class="math inline">\(\eta_i\)</span> and <span class="math inline">\(\varepsilon_i\)</span> are independent: (<span class="math inline">\(\mathbb{C}ov(\eta_i, \varepsilon_i)=0\)</span>).
This is a nice assumption because now we know (see <a href="https://en.wikipedia.org/wiki/Variance#Addition_and_multiplication_by_a_constant">here</a>)
that the variability
of the observed score <span class="math inline">\(Y_i\)</span> is just the sum of the variability of the true score <span class="math inline">\(\eta_i\)</span>
and the variability of the error term <span class="math inline">\(\varepsilon_i\)</span>:</p>
<p><span class="math display">\[ \mathbb{V}ar(Y_i) = \mathbb{V}ar(\eta_i) + \mathbb{V}ar(\varepsilon_i) \]</span>
<span class="math display">\[ \sigma_{Y_i}^2 = \sigma_{\eta_i}^2 + \sigma_{\varepsilon_i}^2 \]</span></p>
<p>We want most of the variability in our observed scores <span class="math inline">\(Y_i\)</span> to be explained by the
true but unobservable scores <span class="math inline">\(\eta_i\)</span>. The measurement error <span class="math inline">\(\varepsilon_i\)</span> should be
be comparatively small. If it is large, we are mostly measuring noise or at least not
what we want to measure.</p>
<p>If you either pull two people with the same true but unobservable score <span class="math inline">\(\eta\)</span> out of the population
or measure the same person twice and the score does not change in between, we can
<strong>define reliability as correlation between these two measurements</strong>:</p>
<p><span class="math display">\[Y_1 = \eta + \varepsilon_1\]</span>
<span class="math display">\[Y_2 = \eta + \varepsilon_2\]</span></p>
<p><span class="math display">\[cor(Y_1, Y_2) = cor(\eta + \varepsilon_1, \eta + \varepsilon_2) =
\frac{Cov(\eta + \varepsilon_1, \eta + \varepsilon_2)}{\sigma_{Y_1}\sigma_{Y_2}}  = \]</span></p>
<p>If we use the <a href="https://en.wikipedia.org/wiki/Covariance#Properties">properties of the covariance</a>,
and the fact that the errors <span class="math inline">\(\varepsilon_1\)</span> and <span class="math inline">\(\varepsilon_2\)</span> are independent, we get:</p>
<p><span class="math display">\[ \frac{Cov(\eta, \eta) + Cov(\eta, \varepsilon_2) + Cov(\varepsilon_1, \eta) + Cov(\varepsilon_1, \varepsilon_2)}{\sigma_{Y_1} \sigma_{Y_2}}  = \]</span>
<span class="math display">\[ \frac{\sigma_{\eta}^2 + 0 + 0 + 0}{\sigma_{Y_1} \sigma_{Y_2}}\]</span></p>
<p>Since <span class="math inline">\(\eta\)</span> is a random variable (we draw a person randomly from the population),
it is well defined to talk about the variance of <span class="math inline">\(\eta\)</span> (i.e., <span class="math inline">\(\sigma_{\eta}^2\)</span>).
I think this aspect may not come across in the book quite so clearly.</p>
<p>Furthermore, it does not matter if I call the measurement <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(Y_2\)</span> or more gerneral
<span class="math inline">\(Y\)</span>, since they have the same variance and true score:</p>
<p><span class="math display">\[\sigma_{Y} = \sigma_{Y_1} = \sigma_{Y_2}\]</span></p>
<p>Hence, it follows that:</p>
<p><span class="math display">\[cor(Y_1, Y_2) =  \frac{\sigma_{\eta}^2}{\sigma_{Y}^2} = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>This is the <strong>intraclass correlation coefficient (ICC)</strong>. It is the proportion of the
true score variability to the total variability. The ICC is a number between 0 and 1 (think about why!).</p>
<p>Depending on how much deviation from the true but unknown <span class="math inline">\(\eta\)</span> we throw into the error term <span class="math inline">\(\varepsilon\)</span>,
you get different versions of the ICC. We will probably stick with the simple versions <span class="math inline">\(ICC_{agreement}\)</span>
and <span class="math inline">\(ICC_{consistency}\)</span> here and make sure we understand those.</p>
<p>Let’s look again at the term for the ICC above and divide the numerator and the denominator by
<span class="math inline">\(\sigma_{\eta}^2\)</span>, which we can do, since it is a positive number:</p>
<p><span class="math display">\[ \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2} =
\frac{1}{1 + \frac{\sigma_{\varepsilon}^2}{\sigma_{\eta}^2}}\]</span></p>
<p>We could call the term <span class="math inline">\(\frac{\sigma_{\varepsilon}^2}{\sigma_{\eta}^2}\)</span> the noise-to-signal ratio.
The higher this ratio, the lower the ICC. The lower the ratio, the higher the ICC.</p>
<ul>
<li>If you increase the noise (measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>) for fixed
true score variability <span class="math inline">\(\sigma_{\eta}^2\)</span>, the ICC decreases, because the denominator
increases.</li>
<li>If you increase the true score variability <span class="math inline">\(\sigma_{\eta}^2\)</span> for fixed noise<span class="math inline">\(\sigma_{\varepsilon}^2\)</span>,
the ICC increases, since the denominator decreases.</li>
</ul>
<p>Btw, we could also divide by <span class="math inline">\(\sigma_{\varepsilon}^2\)</span> and get the signal-to-noise ratio.</p>
<p>At first glance, the following statement seems wrong:</p>
<p>In a very <strong>homogeneous population</strong> (patients have very similar scores/measurements),
the <strong>ICC might be very low</strong>. The reason is that the patient variability <span class="math inline">\(\sigma_{\eta}^2\)</span> is low
and you probably have some measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>.
Hence, if you look at the formula, ICC must be low (for a given measurement error).</p>
<p>On the other hand, if you have a very <strong>heterogeneous population</strong> (patients have rather different
scores/measurements), the <strong>ICC might be very high</strong>.
The reason is that the patient variability <span class="math inline">\(\sigma_{\eta}^2\)</span> is high and you probably
have some measurement error <span class="math inline">\(\sigma_{\varepsilon}^2\)</span>.</p>
<p><strong>What matters is the ratio of the two</strong>, as can be seen from the formula above.</p>
<p>Let’s try to calculate the ICC for our data using a statistical model. There are a couple of different
R packages to do this. We will use the <code>irr</code> package.</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="reliability-and-validity.html#cb271-1" tabindex="-1"></a><span class="fu">library</span>(irr)</span></code></pre></div>
<pre><code>## Loading required package: lpSolve</code></pre>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="reliability-and-validity.html#cb273-1" tabindex="-1"></a>irr<span class="sc">::</span><span class="fu">icc</span>(<span class="fu">as.matrix</span>(df[, <span class="fu">c</span>(<span class="st">&quot;ROMas.Peter&quot;</span>, <span class="st">&quot;ROMas.Mary&quot;</span>)]), </span>
<span id="cb273-2"><a href="reliability-and-validity.html#cb273-2" tabindex="-1"></a>    <span class="at">model =</span> <span class="st">&quot;oneway&quot;</span>, <span class="at">type =</span> <span class="st">&quot;consistency&quot;</span>)</span></code></pre></div>
<pre><code>##  Single Score Intraclass Correlation
## 
##    Model: oneway 
##    Type : consistency 
## 
##    Subjects = 50 
##      Raters = 2 
##      ICC(1) = 0.851
## 
##  F-Test, H0: r0 = 0 ; H1: r0 &gt; 0 
##    F(49,50) = 12.4 , p = 7.31e-16 
## 
##  95%-Confidence Interval for ICC Population Values:
##   0.753 &lt; ICC &lt; 0.913</code></pre>
<p>We get the result: <span class="math inline">\(ICC(1) = 0.851\)</span>.</p>
<p>Since we are regression model experts, we would like to see if we can get the result using the Bayesian
framework.</p>
<p>Below is the model structure.</p>
<p><strong>Model details:</strong></p>
<ul>
<li><span class="math inline">\(ROM_i\)</span> is the observed ROM-score for observation <span class="math inline">\(i\)</span>.
Every patient has two observations (one each from Mary and Peter).
So, for instance <span class="math inline">\(i=1,2\)</span> could be patient <span class="math inline">\(ID=1\)</span>.</li>
<li><span class="math inline">\(\mu_i\)</span> is the expected value of the observed score for patient <span class="math inline">\(ID\)</span>.</li>
<li><span class="math inline">\(\sigma_{\varepsilon}\)</span> is the standard deviation of the measurement error.</li>
<li><span class="math inline">\(\alpha[ID]\)</span> is the patient-specific intercept.
Since every patient has a different intercept and they
come from a normal distribution, we have a <strong>random intercepts model</strong>.</li>
<li><span class="math inline">\(\mu_{\alpha}\)</span> is the mean of the prior for the patient-specific intercepts.
This is the overall mean of the scores.</li>
<li><span class="math inline">\(\sigma_{\alpha}\)</span> is the standard deviation of the patient-specific intercepts.
<strong>This is the patient variability</strong>! The nice thing about presenting a model in this
way is that it’s easier to interpret. <span class="math inline">\(\sigma_{\alpha}\)</span> says how much
the scores of the patients vary in relation to their respective level <span class="math inline">\(\alpha[ID]\)</span>.</li>
</ul>
<p>The <strong><span class="math inline">\(ICC_{consistency}\)</span></strong> is then calculated as the ratio of the between-patient variance and
the total variance:</p>
<p><span class="math display">\[\frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p><span class="math display">\[
\begin{array}{rcl}
ROM_i &amp;\sim&amp; N(\mu_i, \sigma_{\varepsilon}) \\
\mu_i &amp;=&amp; \alpha[ID] \\
\alpha[ID] &amp;\sim&amp; \text{Normal}(\mu_{\alpha}, \sigma_{\alpha}) \\
\mu_{\alpha} &amp;\sim&amp; \text{Normal}(66, 20) \\
\sigma_{\alpha} &amp;\sim&amp; \text{Uniform}(0,20) \\
\sigma_{\varepsilon} &amp;\sim&amp; \text{Uniform}(0,20)
\end{array}
\]</span></p>
<p>We did not even notice it, but this was our first <strong>multilevel regression model</strong>.
It is multilevel due to the extra layer of patient-specific intercepts.
The <strong>observations</strong> are obviously <strong>clustered within patients</strong>, since observations
from the <strong>same patient</strong> are <strong>more similar than observations from different patients</strong>.</p>
<p>Draw model structure … exercise..</p>
<p>This time we fire up the <code>rethinking</code> package and use the <code>ulam</code> function
to fit the model.
This uses Markov Chain Monte Carlo (MCMC) to sample from the posterior
distribution of the parameters.</p>
<ul>
<li><p>The <code>chains</code> argument specifies how many chains we want to run.
A <em>chain</em> is a sequence of points in a space with as many dimensions as there
are parameters in the model. It jumps from one point to the next in this parameter
space and in doing so, visits the points of the posterior approximately in the correct
frequency. <a href="https://blog.revolutionanalytics.com/2013/09/an-animated-peek-into-the-workings-of-bayesian-statistics.html">Here</a>
is an excellent visualization.</p></li>
<li><p>The <code>cores</code> argument specifies how many CPU cores we want to use.
For larger jobs, one can try to parallelize
the chains, which saves some time.</p></li>
</ul>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="reliability-and-validity.html#cb275-1" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb275-2"><a href="reliability-and-validity.html#cb275-2" tabindex="-1"></a><span class="fu">library</span>(tictoc)</span>
<span id="cb275-3"><a href="reliability-and-validity.html#cb275-3" tabindex="-1"></a></span>
<span id="cb275-4"><a href="reliability-and-validity.html#cb275-4" tabindex="-1"></a>df_long <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb275-5"><a href="reliability-and-validity.html#cb275-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="fu">row_number</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb275-6"><a href="reliability-and-validity.html#cb275-6" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(ID,ROMas.Peter, ROMas.Mary) <span class="sc">%&gt;%</span> </span>
<span id="cb275-7"><a href="reliability-and-validity.html#cb275-7" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(ROMas.Peter, ROMas.Mary), </span>
<span id="cb275-8"><a href="reliability-and-validity.html#cb275-8" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">&quot;Rater&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;ROM&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb275-9"><a href="reliability-and-validity.html#cb275-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Rater =</span> <span class="fu">factor</span>(Rater))</span>
<span id="cb275-10"><a href="reliability-and-validity.html#cb275-10" tabindex="-1"></a></span>
<span id="cb275-11"><a href="reliability-and-validity.html#cb275-11" tabindex="-1"></a><span class="fu">tic</span>()</span>
<span id="cb275-12"><a href="reliability-and-validity.html#cb275-12" tabindex="-1"></a>m5<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb275-13"><a href="reliability-and-validity.html#cb275-13" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb275-14"><a href="reliability-and-validity.html#cb275-14" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb275-15"><a href="reliability-and-validity.html#cb275-15" tabindex="-1"></a>    ROM <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb275-16"><a href="reliability-and-validity.html#cb275-16" tabindex="-1"></a>    </span>
<span id="cb275-17"><a href="reliability-and-validity.html#cb275-17" tabindex="-1"></a>    <span class="co"># Patient-specific intercepts (random effects)</span></span>
<span id="cb275-18"><a href="reliability-and-validity.html#cb275-18" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a[ID],  </span>
<span id="cb275-19"><a href="reliability-and-validity.html#cb275-19" tabindex="-1"></a>    a[ID] <span class="sc">~</span> <span class="fu">dnorm</span>(mu_a, sigma_ID),  <span class="co"># Hierarchical structure for patients</span></span>
<span id="cb275-20"><a href="reliability-and-validity.html#cb275-20" tabindex="-1"></a>    </span>
<span id="cb275-21"><a href="reliability-and-validity.html#cb275-21" tabindex="-1"></a>    <span class="co"># Priors for hyperparameters</span></span>
<span id="cb275-22"><a href="reliability-and-validity.html#cb275-22" tabindex="-1"></a>    mu_a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">66</span>, <span class="dv">20</span>),  <span class="co"># Population-level mean</span></span>
<span id="cb275-23"><a href="reliability-and-validity.html#cb275-23" tabindex="-1"></a>    sigma_ID <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">20</span>),  <span class="co"># Between-patient standard deviation</span></span>
<span id="cb275-24"><a href="reliability-and-validity.html#cb275-24" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">20</span>)  <span class="co"># Residual standard deviation</span></span>
<span id="cb275-25"><a href="reliability-and-validity.html#cb275-25" tabindex="-1"></a>  ), </span>
<span id="cb275-26"><a href="reliability-and-validity.html#cb275-26" tabindex="-1"></a>  <span class="at">data =</span> df_long, </span>
<span id="cb275-27"><a href="reliability-and-validity.html#cb275-27" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">8</span>, <span class="at">cores =</span> <span class="dv">4</span></span>
<span id="cb275-28"><a href="reliability-and-validity.html#cb275-28" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Running MCMC with 8 chains, at most 4 in parallel, with 1 thread(s) per chain...
## 
## Chain 1 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 1 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 1 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f41a44805b.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 1</code></pre>
<pre><code>## Chain 2 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 2 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 2 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f41a44805b.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 2</code></pre>
<pre><code>## Chain 3 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 3 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 4 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 4 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 4 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 4 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f41a44805b.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 4</code></pre>
<pre><code>## Chain 1 finished in 0.1 seconds.
## Chain 2 finished in 0.2 seconds.
## Chain 3 finished in 0.1 seconds.
## Chain 4 finished in 0.1 seconds.
## Chain 5 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 5 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 5 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 5 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 5 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 5 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 5 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 5 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 5 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 5 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 5 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 5 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 5 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 5 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f41a44805b.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 5 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 5 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 5</code></pre>
<pre><code>## Chain 6 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 6 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 6 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 6 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 6 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 6 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 6 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 6 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 6 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 6 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 6 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 6 Iteration: 1000 / 1000 [100%]  (Sampling)</code></pre>
<pre><code>## Chain 6 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 6 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f41a44805b.stan&#39;, line 17, column 4 to column 34)</code></pre>
<pre><code>## Chain 6 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 6 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 6</code></pre>
<pre><code>## Chain 7 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 7 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 7 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 7 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 7 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 7 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 7 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 7 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 7 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 7 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 7 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 7 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 8 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 8 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 8 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 8 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 8 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 8 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 5 finished in 0.1 seconds.
## Chain 6 finished in 0.1 seconds.
## Chain 7 finished in 0.1 seconds.
## Chain 8 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 8 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 8 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 8 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 8 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 finished in 0.1 seconds.
## 
## All 8 chains finished successfully.
## Mean chain execution time: 0.1 seconds.
## Total execution time: 0.6 seconds.</code></pre>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="reliability-and-validity.html#cb307-1" tabindex="-1"></a><span class="fu">toc</span>() <span class="co"># 7s</span></span></code></pre></div>
<pre><code>## 6.948 sec elapsed</code></pre>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="reliability-and-validity.html#cb309-1" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.1</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##               mean        sd      5.5%     94.5%      rhat ess_bulk
## a[1]     67.722244 4.9090800 59.884240 75.424230 1.0011883 6619.262
## a[2]     64.111654 4.7840605 56.528447 71.776798 1.0034783 6191.276
## a[3]     86.987105 4.8248501 79.310842 94.721499 1.0021836 6533.691
## a[4]     76.488312 4.8772869 68.688592 84.377506 1.0004241 6088.506
## a[5]     58.652587 4.9146668 50.800481 66.376233 1.0057245 6894.371
## a[6]     69.286318 4.9001887 61.446915 77.135439 1.0023860 6440.228
## a[7]     69.630175 4.7214488 62.093989 77.274188 1.0042853 6102.224
## a[8]     67.364715 4.8073624 59.760551 74.940179 1.0004233 6926.255
## a[9]     70.982913 4.8029119 63.473921 78.838160 1.0021779 6096.437
## a[10]    81.123297 4.6829024 73.463408 88.601603 1.0000833 5882.855
## a[11]    70.525946 4.7789205 62.916758 78.015190 1.0027020 6057.395
## a[12]    42.158971 4.9255574 34.330380 50.142874 1.0052952 5608.430
## a[13]    86.981146 4.8049263 79.173926 94.829309 1.0006401 5697.280
## a[14]    74.665706 4.6060512 67.261235 81.970150 1.0042568 6217.659
## a[15]    76.383198 4.8629608 68.375808 84.099854 1.0019507 5393.146
## a[16]    34.941636 4.9924846 27.056167 43.018477 1.0015714 6091.685
## a[17]    84.803446 4.7374711 77.144124 92.406944 0.9993908 4742.513
## a[18]    64.997487 4.9643186 56.943773 72.939016 1.0035173 6046.231
## a[19]    63.285164 4.9025730 55.533948 71.178041 1.0013061 5093.825
## a[20]    79.685208 5.0087033 71.658232 87.571054 1.0025818 5732.622
## a[21]    30.284397 4.9534314 22.471539 38.175759 1.0029669 4993.642
## a[22]    62.717165 4.8429270 55.056809 70.508550 1.0042888 5186.047
## a[23]    67.369138 4.7935870 59.691637 75.021504 1.0015468 5712.044
## a[24]    81.364895 4.6500222 73.951702 88.744605 1.0010820 5840.154
## a[25]    54.960936 4.6723859 47.304353 62.472893 1.0031483 6486.986
## a[26]    67.484558 4.8629666 59.694329 75.237344 1.0024718 5631.800
## a[27]    75.662864 4.6822039 68.289372 83.149005 1.0015293 5142.724
## a[28]    81.458669 4.7261292 73.931357 89.044628 1.0007963 6429.453
## a[29]    46.319123 4.9454046 38.515295 54.285881 1.0011816 5884.281
## a[30]    61.257367 4.7772157 53.562560 68.978274 1.0023302 5689.914
## a[31]    23.509215 4.9033830 15.777376 31.510781 1.0033955 4020.937
## a[32]    74.135907 4.9851734 66.120570 81.958539 1.0022234 6227.534
## a[33]    70.503386 4.7654367 62.891725 78.072130 1.0023102 5314.875
## a[34]    76.514259 4.7673813 69.060676 84.004384 1.0056486 6295.756
## a[35]    75.552330 4.7650873 68.063417 83.238239 1.0059815 6458.817
## a[36]    69.318470 4.8028313 61.733604 76.842796 1.0019923 5624.692
## a[37]    49.567778 4.8517137 42.000534 57.348616 1.0001428 5345.948
## a[38]    73.807516 4.8704217 66.012632 81.610347 1.0014698 5593.351
## a[39]    72.757513 4.8058223 65.331446 80.543411 0.9996477 6046.893
## a[40]    45.817525 4.8801249 38.090789 53.659197 1.0017618 5810.945
## a[41]    73.683223 4.8798317 65.754844 81.586076 0.9997154 5788.226
## a[42]    26.096569 5.0020037 18.151000 34.085055 1.0035820 5645.769
## a[43]    32.929828 4.9839276 25.060965 40.934064 1.0009925 4969.622
## a[44]    74.142579 4.8767249 66.482373 81.844996 1.0027673 5518.837
## a[45]    76.914062 4.8315152 69.190795 84.479135 1.0021492 5799.564
## a[46]    73.639372 4.7714194 66.006190 81.297628 1.0014867 5772.895
## a[47]    55.859204 4.8616217 48.241338 63.875677 1.0018038 5633.257
## a[48]    69.603460 4.7802544 61.990560 77.160122 1.0024286 5065.542
## a[49]    72.402414 4.6825454 65.012180 79.784921 1.0015697 5911.021
## a[50]    72.770000 4.8603442 65.014248 80.455220 1.0029222 7919.236
## mu_a     65.555333 2.4626739 61.598423 69.494927 1.0017301 4186.431
## sigma_ID 16.613184 1.6346644 14.010696 19.244560 1.0024463 1915.575
## sigma     7.081393 0.7331837  6.011486  8.331337 1.0004015 2066.538</code></pre>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="reliability-and-validity.html#cb311-1" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.1</span>)</span>
<span id="cb311-2"><a href="reliability-and-validity.html#cb311-2" tabindex="-1"></a>var_patients <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_ID<span class="sc">^</span><span class="dv">2</span>)  <span class="co"># Between-patient variance</span></span>
<span id="cb311-3"><a href="reliability-and-validity.html#cb311-3" tabindex="-1"></a>var_residual <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span>)     <span class="co"># Residual variance</span></span>
<span id="cb311-4"><a href="reliability-and-validity.html#cb311-4" tabindex="-1"></a>var_patients <span class="sc">/</span> (var_patients <span class="sc">+</span> var_residual) <span class="co"># ICC</span></span></code></pre></div>
<pre><code>## [1] 0.8461117</code></pre>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="reliability-and-validity.html#cb313-1" tabindex="-1"></a><span class="co"># 0.846</span></span>
<span id="cb313-2"><a href="reliability-and-validity.html#cb313-2" tabindex="-1"></a><span class="co"># not too bad; very close to the result from the irr package</span></span></code></pre></div>
<p>In the output from <code>precis(m5.1, depth = 2)</code> above we see</p>
<ul>
<li>all 50 intercept estimates for each patient: <code>a[ID]</code></li>
<li><code>mu_a</code>is the overall intercept.</li>
<li><code>sigma_ID</code> is the <strong>patient variability</strong>.</li>
<li><code>sigma</code> is the <strong>residual variability</strong>.</li>
</ul>
<p>We just square the sigmas to get the variances.</p>
<p>The trick to do these calculations by “hand” is to get the
variance decomposition correct.
We stumbled upon variance decomposition in the context of ANOVA,
where we decomposed the total variance into the regression variance
and the residual variance. Here, we decompose the total variance
into the between-patient variance and the residual variance.</p>
<p>Remember: In the background, there is just a statistical model to predict
the outcome. Depending on the predictors, we get different models and
probably different ICCs</p>
<p>We can also estimate a <strong>random intercept model</strong> with the <code>lme4</code> package using
the command <code>lmer</code>in the Frequentist framework. No priors.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="reliability-and-validity.html#cb314-1" tabindex="-1"></a><span class="fu">library</span>(lme4)</span></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="reliability-and-validity.html#cb318-1" tabindex="-1"></a>m5<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lmer</span>(ROM <span class="sc">~</span> (<span class="dv">1</span><span class="sc">|</span>ID), <span class="at">data =</span> df_long)</span>
<span id="cb318-2"><a href="reliability-and-validity.html#cb318-2" tabindex="-1"></a><span class="fu">summary</span>(m5<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: ROM ~ (1 | ID)
##    Data: df_long
## 
## REML criterion at convergence: 791
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.91875 -0.44821  0.00964  0.51325  1.47941 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  ID       (Intercept) 270.99   16.462  
##  Residual              47.35    6.881  
## Number of obs: 100, groups:  ID, 50
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   65.590      2.428   27.02</code></pre>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="reliability-and-validity.html#cb320-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">VarCorr</span>(m5<span class="fl">.2</span>), <span class="at">comp =</span> <span class="st">&quot;Variance&quot;</span>)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance
##  ID       (Intercept) 270.99  
##  Residual              47.35</code></pre>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="reliability-and-validity.html#cb322-1" tabindex="-1"></a><span class="co"># ICC = </span></span>
<span id="cb322-2"><a href="reliability-and-validity.html#cb322-2" tabindex="-1"></a><span class="fl">270.99</span> <span class="sc">/</span> (<span class="fl">270.99</span> <span class="sc">+</span> <span class="fl">47.35</span>) <span class="co"># </span></span></code></pre></div>
<pre><code>## [1] 0.8512597</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="reliability-and-validity.html#cb324-1" tabindex="-1"></a><span class="co"># 0.8512597</span></span>
<span id="cb324-2"><a href="reliability-and-validity.html#cb324-2" tabindex="-1"></a><span class="co"># -&gt; exactly the same result as the irr package</span></span></code></pre></div>
<p>The expression <code>Formula: ROM ~ (1 | ID)</code> specifies that we want to fit a model with
a random intercept. This means that every patient (ID) gets its own intercept
which is drawn from a normal distribution. We will probably talk about this in the
next lecture (Methodenvertiefung) in greater detail.</p>
<p>So far, we have only looked at the <strong><span class="math inline">\(ICC_{consistency}\)</span></strong> (see also page 106 in the book).
There, we have not yet explicitely considered a bias (=systematic difference
between the raters) that the raters could have. In the book,
they introduce a bias of 5 degrees (Mary measures 5 degrees more than Peter on average).</p>
<p><strong>There is also the <span class="math inline">\(ICC_{agreement}\)</span></strong>, which explicitely considers this
(systematic) difference that could occur between the raters.
This results in an extra term in the demoniator
of the ICC, an additional variance component:</p>
<p><span class="math display">\[ ICC_{agreement} = \frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 +
\mathbf{\sigma_{rater}^2} + \sigma_{\varepsilon}^2}\]</span></p>
<p>where <span class="math inline">\(\sigma_{rater}^2\)</span> is the variance due to systematic rater differences.</p>
<p>We will now introduce the 5 degree bias and use our Bayesian
framework to estimate the <span class="math inline">\(ICC_{agreement}\)</span>.
By introducing a bias, we should see
a lower ICC (agreement). Note, that the prediction quality of Mary’s scores
given Peter’s scores should not change, since we would only shift Mary’s scores
down by 5 degrees, which would not disturb the linear regression model. We can
always move around the points to where we want them to be. We do that for instance
when we scale or standardize the data.</p>
<p>Admitted, the Bayesian version in this case takes longer and is more complex.
The advantage is still that it’s fully probabilistic and one could work with
detailed prior information, especially for smaller smaple sizes.</p>
<p>Anyhow, let’s try to give the model equations considering
the introduced bias:</p>
<p><span class="math display">\[
\begin{array}{rcl}
ROM_i &amp;\sim&amp; N(\mu_i, \sigma_{\varepsilon}) \\
\mu_i &amp;=&amp; \alpha[ID] + \beta[Rater] \\
\alpha[ID] &amp;\sim&amp; \text{Normal}(\mu_{\alpha}, \sigma_{\alpha}) \\
\beta[Rater] &amp;\sim&amp; \text{Normal}(0, \sigma_{\beta}) \\
\mu_{\alpha} &amp;\sim&amp; \text{Normal}(66, 20) \\
\sigma_{\alpha} &amp;\sim&amp; \text{Exp}(0.5) \\
\sigma_{\beta} &amp;\sim&amp; \text{Exp}(1) \\
\sigma_{\varepsilon} &amp;\sim&amp; \text{Exp}(1)
\end{array}
\]</span></p>
<p>As you can see, <span class="math inline">\(\mu_i\)</span> now consists of the patient-specific intercept <span class="math inline">\(\alpha[ID]\)</span>
(everyone of the 50 patients gets one)
and the rater-specific effect <span class="math inline">\(\beta[Rater]\)</span> (Mary and Peter get one).
So, in total, we have <strong>three sources of variability</strong>:</p>
<ul>
<li>the patient variability <span class="math inline">\(\sigma_{\alpha}\)</span>,</li>
<li>the rater variability <span class="math inline">\(\sigma_{\beta}\)</span>,</li>
<li>and the residual variability <span class="math inline">\(\sigma_{\varepsilon}\)</span>.</li>
</ul>
<p>Note, that if Peter measures each of the 50 patients twice,
the systematic difference between Peter’s measurements would
be zero. Of course, one could be creative and think of
a learning effect or something.</p>
<p>Draw model structure … exercise..</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="reliability-and-validity.html#cb325-1" tabindex="-1"></a>df_long_bias <span class="ot">&lt;-</span> df_long <span class="sc">%&gt;%</span></span>
<span id="cb325-2"><a href="reliability-and-validity.html#cb325-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ROM =</span> ROM <span class="sc">+</span> <span class="fu">ifelse</span>(Rater <span class="sc">==</span> <span class="st">&quot;ROMas.Mary&quot;</span>, <span class="dv">5</span>, <span class="dv">0</span>))</span>
<span id="cb325-3"><a href="reliability-and-validity.html#cb325-3" tabindex="-1"></a><span class="fu">head</span>(df_long_bias)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 3
##      ID Rater         ROM
##   &lt;int&gt; &lt;fct&gt;       &lt;dbl&gt;
## 1     1 ROMas.Peter    66
## 2     1 ROMas.Mary     75
## 3     2 ROMas.Peter    65
## 4     2 ROMas.Mary     68
## 5     3 ROMas.Peter    96
## 6     3 ROMas.Mary     87</code></pre>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="reliability-and-validity.html#cb327-1" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb327-2"><a href="reliability-and-validity.html#cb327-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb327-3"><a href="reliability-and-validity.html#cb327-3" tabindex="-1"></a>m5<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb327-4"><a href="reliability-and-validity.html#cb327-4" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb327-5"><a href="reliability-and-validity.html#cb327-5" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb327-6"><a href="reliability-and-validity.html#cb327-6" tabindex="-1"></a>    ROM <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma_eps),</span>
<span id="cb327-7"><a href="reliability-and-validity.html#cb327-7" tabindex="-1"></a>    </span>
<span id="cb327-8"><a href="reliability-and-validity.html#cb327-8" tabindex="-1"></a>    <span class="co"># Model for mean ROM with patient and rater effects</span></span>
<span id="cb327-9"><a href="reliability-and-validity.html#cb327-9" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> alpha[ID] <span class="sc">+</span> beta[Rater],  </span>
<span id="cb327-10"><a href="reliability-and-validity.html#cb327-10" tabindex="-1"></a>    </span>
<span id="cb327-11"><a href="reliability-and-validity.html#cb327-11" tabindex="-1"></a>    <span class="co"># Patient-specific random effects</span></span>
<span id="cb327-12"><a href="reliability-and-validity.html#cb327-12" tabindex="-1"></a>    alpha[ID] <span class="sc">~</span> <span class="fu">dnorm</span>(mu_alpha, sigma_alpha),  </span>
<span id="cb327-13"><a href="reliability-and-validity.html#cb327-13" tabindex="-1"></a>    </span>
<span id="cb327-14"><a href="reliability-and-validity.html#cb327-14" tabindex="-1"></a>    <span class="co"># Rater effect (Peter/Mary)</span></span>
<span id="cb327-15"><a href="reliability-and-validity.html#cb327-15" tabindex="-1"></a>    beta[Rater] <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, sigma_beta),  </span>
<span id="cb327-16"><a href="reliability-and-validity.html#cb327-16" tabindex="-1"></a>    </span>
<span id="cb327-17"><a href="reliability-and-validity.html#cb327-17" tabindex="-1"></a>    <span class="co"># Priors for hyperparameters</span></span>
<span id="cb327-18"><a href="reliability-and-validity.html#cb327-18" tabindex="-1"></a>    mu_alpha <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">66</span>, <span class="dv">10</span>),  <span class="co"># Population mean ROM</span></span>
<span id="cb327-19"><a href="reliability-and-validity.html#cb327-19" tabindex="-1"></a>    sigma_alpha <span class="sc">~</span> <span class="fu">dexp</span>(<span class="fl">0.5</span>),  <span class="co"># Between-patient SD (less aggressive shrinkage)</span></span>
<span id="cb327-20"><a href="reliability-and-validity.html#cb327-20" tabindex="-1"></a>    sigma_beta <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>),   <span class="co"># Rater SD (better regularization)</span></span>
<span id="cb327-21"><a href="reliability-and-validity.html#cb327-21" tabindex="-1"></a>    sigma_eps <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>)     <span class="co"># Residual SD (prevents over-shrinkage)</span></span>
<span id="cb327-22"><a href="reliability-and-validity.html#cb327-22" tabindex="-1"></a>  ), </span>
<span id="cb327-23"><a href="reliability-and-validity.html#cb327-23" tabindex="-1"></a>  <span class="at">data =</span> df_long_bias, </span>
<span id="cb327-24"><a href="reliability-and-validity.html#cb327-24" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">8</span>, <span class="at">cores =</span> <span class="dv">4</span></span>
<span id="cb327-25"><a href="reliability-and-validity.html#cb327-25" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Running MCMC with 8 chains, at most 4 in parallel, with 1 thread(s) per chain...
## 
## Chain 1 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 1 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 1 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 1 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 1 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 1 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 1 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling)</code></pre>
<pre><code>## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 1 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f43a4610b8.stan&#39;, line 21, column 4 to column 45)</code></pre>
<pre><code>## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 1</code></pre>
<pre><code>## Chain 2 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 2 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 2 Iteration: 200 / 1000 [ 20%]  (Warmup)</code></pre>
<pre><code>## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f43a4610b8.stan&#39;, line 21, column 4 to column 45)</code></pre>
<pre><code>## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 2</code></pre>
<pre><code>## Chain 3 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 3 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 3 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 4 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 4 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 4 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 4 Iteration: 300 / 1000 [ 30%]  (Warmup)</code></pre>
<pre><code>## Chain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 4 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f43a4610b8.stan&#39;, line 21, column 4 to column 45)</code></pre>
<pre><code>## Chain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 4</code></pre>
<pre><code>## Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 2 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 2 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 2 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 2 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 2 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 3 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 3 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 3 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 3 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 3 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 4 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 4 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 4 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 4 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 1 finished in 0.2 seconds.
## Chain 2 finished in 0.3 seconds.
## Chain 3 finished in 0.2 seconds.
## Chain 4 finished in 0.2 seconds.
## Chain 5 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 5 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 5 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 5 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 5 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 5 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 5 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 5 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 5 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 5 Iteration: 800 / 1000 [ 80%]  (Sampling)</code></pre>
<pre><code>## Chain 5 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 5 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f43a4610b8.stan&#39;, line 21, column 4 to column 45)</code></pre>
<pre><code>## Chain 5 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 5 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 5</code></pre>
<pre><code>## Chain 6 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 6 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 6 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 6 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 6 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 6 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 6 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 6 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 6 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 7 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 7 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 7 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 7 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 7 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 7 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 7 Iteration: 501 / 1000 [ 50%]  (Sampling)</code></pre>
<pre><code>## Chain 7 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</code></pre>
<pre><code>## Chain 7 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in &#39;/var/folders/pm/jd6n6gj10371_bml1gh8sc5w0000gn/T/Rtmpd8l8iU/model-f8f43a4610b8.stan&#39;, line 21, column 4 to column 45)</code></pre>
<pre><code>## Chain 7 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</code></pre>
<pre><code>## Chain 7 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</code></pre>
<pre><code>## Chain 7</code></pre>
<pre><code>## Chain 8 Iteration:   1 / 1000 [  0%]  (Warmup) 
## Chain 8 Iteration: 100 / 1000 [ 10%]  (Warmup) 
## Chain 5 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 5 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 5 finished in 0.2 seconds.
## Chain 6 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 6 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 6 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 7 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 7 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 7 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 7 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 7 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 Iteration: 200 / 1000 [ 20%]  (Warmup) 
## Chain 8 Iteration: 300 / 1000 [ 30%]  (Warmup) 
## Chain 8 Iteration: 400 / 1000 [ 40%]  (Warmup) 
## Chain 8 Iteration: 500 / 1000 [ 50%]  (Warmup) 
## Chain 8 Iteration: 501 / 1000 [ 50%]  (Sampling) 
## Chain 8 Iteration: 600 / 1000 [ 60%]  (Sampling) 
## Chain 8 Iteration: 700 / 1000 [ 70%]  (Sampling) 
## Chain 8 Iteration: 800 / 1000 [ 80%]  (Sampling) 
## Chain 8 Iteration: 900 / 1000 [ 90%]  (Sampling) 
## Chain 6 finished in 0.2 seconds.
## Chain 7 finished in 0.2 seconds.
## Chain 8 Iteration: 1000 / 1000 [100%]  (Sampling) 
## Chain 8 finished in 0.2 seconds.
## 
## All 8 chains finished successfully.
## Mean chain execution time: 0.2 seconds.
## Total execution time: 0.8 seconds.</code></pre>
<pre><code>## Warning: 27 of 4000 (1.0%) transitions ended with a divergence.
## See https://mc-stan.org/misc/warnings for details.</code></pre>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="reliability-and-validity.html#cb360-1" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.2</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##                  mean        sd       5.5%      94.5%     rhat  ess_bulk
## alpha[1]    70.221230 4.6957078 62.9122250 77.6751330 1.003921 3956.8010
## alpha[2]    66.637192 4.7935979 59.2921655 74.3219425 1.000703 4048.1323
## alpha[3]    89.391211 4.8460529 81.8305935 96.9301420 1.001484 3581.3337
## alpha[4]    79.068129 4.7090695 71.7267400 86.7491720 1.002625 4088.4617
## alpha[5]    61.248545 4.6824417 53.8962900 68.7503010 1.002206 3886.9310
## alpha[6]    71.711300 4.5314894 64.4525160 79.0005630 1.001403 3806.2065
## alpha[7]    72.121798 4.7349544 64.6055805 79.6941110 1.001856 3482.5502
## alpha[8]    69.834714 4.7037178 62.3043635 77.3545565 1.000583 4054.8858
## alpha[9]    73.526363 4.7369985 66.0854635 81.0876520 1.001352 3708.7551
## alpha[10]   83.497318 4.7172575 76.0272720 91.0849000 1.001394 3871.4522
## alpha[11]   73.114282 4.6041905 65.8139360 80.4195110 1.002261 3330.7789
## alpha[12]   44.827995 4.8132889 37.2627160 52.4649335 1.003939 3774.3717
## alpha[13]   89.401919 4.7509654 81.8033940 96.8927025 1.001166 3733.9925
## alpha[14]   77.155674 4.7663782 69.3451470 84.8327385 1.002594 3611.6344
## alpha[15]   78.928227 4.8283770 71.2416295 86.6386025 1.005149 3462.8282
## alpha[16]   37.537016 4.8929538 29.6438890 45.4816100 1.000967 3802.3178
## alpha[17]   87.205983 4.6947001 79.8024680 94.7725850 1.004141 3205.6678
## alpha[18]   67.618180 4.6490608 60.4495525 74.8906485 1.000691 3565.7257
## alpha[19]   65.734938 4.7038246 58.2243970 73.1307710 1.003272 3021.3632
## alpha[20]   82.148125 4.6634709 74.8132215 89.4844660 1.001809 3525.2622
## alpha[21]   32.959556 4.7365812 25.6872720 40.6902550 1.000230 3896.3144
## alpha[22]   65.312545 4.7691775 57.6339360 72.9769385 1.001701 3888.3018
## alpha[23]   69.922455 4.6557324 62.4829305 77.3353785 1.004454 3949.3830
## alpha[24]   84.028041 4.8666565 76.4453060 91.8557125 1.002520 4582.8271
## alpha[25]   57.576782 4.6027933 50.1384940 65.0507070 1.003696 3883.0937
## alpha[26]   69.844403 4.5423390 62.4724325 77.0730070 1.002214 3588.0981
## alpha[27]   78.181829 4.6438020 70.9217780 85.6579100 1.000977 3573.7990
## alpha[28]   83.976099 4.7519956 76.3497625 91.4832750 1.000891 3836.6036
## alpha[29]   48.888864 4.6981990 41.3078680 56.4819905 1.001334 4153.8714
## alpha[30]   63.812328 4.7111640 56.4071725 71.2587825 1.003047 3935.6824
## alpha[31]   26.098770 4.8818137 18.3637725 33.9304330 1.003445 4068.8549
## alpha[32]   76.676408 4.7365322 69.0211035 83.9915570 1.002364 3823.5694
## alpha[33]   73.055353 4.6273537 65.9705020 80.5753430 1.002063 4039.5757
## alpha[34]   78.963166 4.7676436 71.3900570 86.3736705 1.001748 3403.3517
## alpha[35]   78.075230 4.7744829 70.5443095 85.7926805 1.001281 4222.4407
## alpha[36]   71.652651 4.7601329 64.0808175 79.2662110 1.000708 4471.9540
## alpha[37]   52.084764 4.7084537 44.8942315 59.7080135 1.002348 3439.9837
## alpha[38]   76.121385 4.8822293 68.3599335 83.7502705 1.002290 4006.6888
## alpha[39]   75.451394 4.7905587 67.7880930 82.8390550 1.000887 3454.6782
## alpha[40]   48.408307 4.7026185 40.9218930 56.1687365 1.003060 3999.9664
## alpha[41]   76.176540 4.6262898 68.7745580 83.5991630 1.004537 3963.8804
## alpha[42]   28.812970 4.7775508 21.1928615 36.4243750 1.003746 3855.7962
## alpha[43]   35.646945 4.6876761 28.1427865 43.0427785 1.000564 4114.5370
## alpha[44]   76.736915 4.6819911 69.0549725 83.9337520 1.003016 3594.7244
## alpha[45]   79.377066 4.6099939 71.8918425 86.7122600 1.001080 4016.1217
## alpha[46]   76.266121 4.6936374 68.9066090 83.8324250 1.000442 4007.8677
## alpha[47]   58.467633 4.5906174 51.1480830 65.6998370 1.002588 3396.4658
## alpha[48]   72.114214 4.7995591 64.4240875 79.7356615 1.005283 3715.8719
## alpha[49]   74.771082 4.6137731 67.3251525 82.0455495 1.001963 3457.0385
## alpha[50]   75.414102 4.7692631 67.7589025 83.1030340 1.001202 4211.2151
## beta[1]      1.196482 1.4699703 -0.7591575  3.6725132 1.005792  932.0193
## beta[2]     -1.260339 1.5058841 -3.8538230  0.6600649 1.007244  857.8581
## mu_alpha    67.979401 2.5706977 63.9069175 72.0885400 1.003032 1842.7425
## sigma_alpha 15.457249 1.6142987 13.1380645 18.2104485 1.000383 4277.2078
## sigma_beta   1.685571 1.0527940  0.3547305  3.5587972 1.001191 1581.1771
## sigma_eps    6.713486 0.6434269  5.7619659  7.7933864 1.004713 2175.7641</code></pre>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="reliability-and-validity.html#cb362-1" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 52 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##                  mean        sd       5.5%     94.5%     rhat ess_bulk
## mu_alpha    67.979401 2.5706977 63.9069175 72.088540 1.003032 1842.742
## sigma_alpha 15.457249 1.6142987 13.1380645 18.210449 1.000383 4277.208
## sigma_beta   1.685571 1.0527940  0.3547305  3.558797 1.001191 1581.177
## sigma_eps    6.713486 0.6434269  5.7619659  7.793386 1.004713 2175.764</code></pre>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="reliability-and-validity.html#cb365-1" tabindex="-1"></a><span class="co"># check systematic difference for rater in posterior</span></span>
<span id="cb365-2"><a href="reliability-and-validity.html#cb365-2" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.2</span>)</span>
<span id="cb365-3"><a href="reliability-and-validity.html#cb365-3" tabindex="-1"></a><span class="fu">mean</span>(post<span class="sc">$</span>beta[,<span class="dv">1</span>] <span class="sc">-</span> post<span class="sc">$</span>beta[,<span class="dv">2</span>])  </span></code></pre></div>
<pre><code>## [1] 2.456821</code></pre>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="reliability-and-validity.html#cb367-1" tabindex="-1"></a><span class="co"># ICC agreement:</span></span>
<span id="cb367-2"><a href="reliability-and-validity.html#cb367-2" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.2</span>)</span>
<span id="cb367-3"><a href="reliability-and-validity.html#cb367-3" tabindex="-1"></a>(var_patients <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_alpha<span class="sc">^</span><span class="dv">2</span>))  <span class="co"># Between-patient variance</span></span></code></pre></div>
<pre><code>## [1] 241.5319</code></pre>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="reliability-and-validity.html#cb369-1" tabindex="-1"></a>(var_raters <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_beta<span class="sc">^</span><span class="dv">2</span>))     <span class="co"># Rater variance</span></span></code></pre></div>
<pre><code>## [1] 3.949248</code></pre>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="reliability-and-validity.html#cb371-1" tabindex="-1"></a>(var_residual <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>sigma_eps<span class="sc">^</span><span class="dv">2</span>))    <span class="co"># Residual variance</span></span></code></pre></div>
<pre><code>## [1] 45.48479</code></pre>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="reliability-and-validity.html#cb373-1" tabindex="-1"></a><span class="co"># ICC_agreement = </span></span>
<span id="cb373-2"><a href="reliability-and-validity.html#cb373-2" tabindex="-1"></a>var_patients <span class="sc">/</span> (var_patients <span class="sc">+</span> var_raters <span class="sc">+</span> var_residual)</span></code></pre></div>
<pre><code>## [1] 0.8301037</code></pre>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="reliability-and-validity.html#cb375-1" tabindex="-1"></a><span class="co"># 0.8033613 (sigma_alpha ~ dexp(1))</span></span>
<span id="cb375-2"><a href="reliability-and-validity.html#cb375-2" tabindex="-1"></a><span class="co"># 0.83 (sigma_alpha ~ dexp(0.5))</span></span>
<span id="cb375-3"><a href="reliability-and-validity.html#cb375-3" tabindex="-1"></a></span>
<span id="cb375-4"><a href="reliability-and-validity.html#cb375-4" tabindex="-1"></a><span class="co"># ICC (Single_fixed_raters) = ICC3 in psych output = </span></span>
<span id="cb375-5"><a href="reliability-and-validity.html#cb375-5" tabindex="-1"></a>var_patients <span class="sc">/</span> (var_patients <span class="sc">+</span> var_residual)</span></code></pre></div>
<pre><code>## [1] 0.8415256</code></pre>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="reliability-and-validity.html#cb377-1" tabindex="-1"></a><span class="co"># 0.8415256</span></span></code></pre></div>
<p>It should be noted that this ICC is very sensitive to the choice of the prior.
If you choose too agressive priors for the standard deviations <span class="math inline">\(\sigma_{\alpha},
\sigma_{\beta}, \sigma_{\varepsilon}\)</span>, you will get a too low ICC.</p>
<p>We will proably talk about this in the next lecture (Methodenvertiefung) in greater detail.
I have played around a little with the parameters in the exponential priors
to get the desired result which compares nicely to the two alternative methods below:
using the <code>psych</code> package and with the <code>lmer</code>
package. Both use a Frequentist random intercept model in the background.
Using a package like <code>psych</code> just gives a more convenient interface to
elicit the ICC.</p>
<p><strong><code>psych</code> package</strong>:</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="reliability-and-validity.html#cb378-1" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb378-2"><a href="reliability-and-validity.html#cb378-2" tabindex="-1"></a><span class="co"># needs wide format</span></span>
<span id="cb378-3"><a href="reliability-and-validity.html#cb378-3" tabindex="-1"></a><span class="fu">conflicts_prefer</span>(dplyr<span class="sc">::</span>select)</span></code></pre></div>
<pre><code>## [conflicted] Will prefer dplyr::select over any other package.</code></pre>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="reliability-and-validity.html#cb380-1" tabindex="-1"></a>df_wide <span class="ot">&lt;-</span> df_long_bias <span class="sc">%&gt;%</span></span>
<span id="cb380-2"><a href="reliability-and-validity.html#cb380-2" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Rater, <span class="at">values_from =</span> ROM)</span>
<span id="cb380-3"><a href="reliability-and-validity.html#cb380-3" tabindex="-1"></a>df_wide_values <span class="ot">&lt;-</span> df_wide <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>ID)</span>
<span id="cb380-4"><a href="reliability-and-validity.html#cb380-4" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">ICC</span>(df_wide_values) <span class="co"># ICC1 = 0.83</span></span></code></pre></div>
<pre><code>## Call: psych::ICC(x = df_wide_values)
## 
## Intraclass correlation coefficients 
##                          type  ICC  F df1 df2       p lower bound upper bound
## Single_raters_absolute   ICC1 0.83 11  49  50 1.1e-14        0.72        0.90
## Single_random_raters     ICC2 0.83 12  49  49 1.4e-15        0.71        0.91
## Single_fixed_raters      ICC3 0.85 12  49  49 1.4e-15        0.75        0.91
## Average_raters_absolute ICC1k 0.91 11  49  50 1.1e-14        0.84        0.95
## Average_random_raters   ICC2k 0.91 12  49  49 1.4e-15        0.83        0.95
## Average_fixed_raters    ICC3k 0.92 12  49  49 1.4e-15        0.86        0.95
## 
##  Number of subjects = 50     Number of Judges =  2
## See the help file for a discussion of the other 4 McGraw and Wong estimates,</code></pre>
<p><strong><code>lmer</code> package</strong>:</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="reliability-and-validity.html#cb382-1" tabindex="-1"></a><span class="co"># _lmer------</span></span>
<span id="cb382-2"><a href="reliability-and-validity.html#cb382-2" tabindex="-1"></a>m5<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lmer</span>(ROM <span class="sc">~</span> (<span class="dv">1</span> <span class="sc">|</span> ID) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Rater), <span class="at">data =</span> df_long_bias)</span>
<span id="cb382-3"><a href="reliability-and-validity.html#cb382-3" tabindex="-1"></a><span class="fu">summary</span>(m5<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: ROM ~ (1 | ID) + (1 | Rater)
##    Data: df_long_bias
## 
## REML criterion at convergence: 793.2
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.87448 -0.46270  0.00272  0.57820  1.45008 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  ID       (Intercept) 270.882  16.458  
##  Rater    (Intercept)   6.193   2.489  
##  Residual              47.557   6.896  
## Number of obs: 100, groups:  ID, 50; Rater, 2
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   68.090      2.998   22.71</code></pre>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="reliability-and-validity.html#cb384-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">VarCorr</span>(m5<span class="fl">.3</span>), <span class="at">comp =</span> <span class="st">&quot;Variance&quot;</span>)</span></code></pre></div>
<pre><code>##  Groups   Name        Variance
##  ID       (Intercept) 270.882 
##  Rater    (Intercept)   6.193 
##  Residual              47.557</code></pre>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="reliability-and-validity.html#cb386-1" tabindex="-1"></a><span class="co"># Groups   Name        Variance</span></span>
<span id="cb386-2"><a href="reliability-and-validity.html#cb386-2" tabindex="-1"></a><span class="co"># ID       (Intercept) 270.882 </span></span>
<span id="cb386-3"><a href="reliability-and-validity.html#cb386-3" tabindex="-1"></a><span class="co"># Rater    (Intercept)   6.193 </span></span>
<span id="cb386-4"><a href="reliability-and-validity.html#cb386-4" tabindex="-1"></a><span class="co"># Residual              47.557 </span></span>
<span id="cb386-5"><a href="reliability-and-validity.html#cb386-5" tabindex="-1"></a></span>
<span id="cb386-6"><a href="reliability-and-validity.html#cb386-6" tabindex="-1"></a></span>
<span id="cb386-7"><a href="reliability-and-validity.html#cb386-7" tabindex="-1"></a><span class="co"># ICC (Single_random_raters) = ICC2 in psych output</span></span>
<span id="cb386-8"><a href="reliability-and-validity.html#cb386-8" tabindex="-1"></a><span class="fl">270.882</span> <span class="sc">/</span> (<span class="fl">270.882</span> <span class="sc">+</span> <span class="fl">6.193</span> <span class="sc">+</span> <span class="fl">47.557</span>) <span class="co"># </span></span></code></pre></div>
<pre><code>## [1] 0.8344279</code></pre>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="reliability-and-validity.html#cb388-1" tabindex="-1"></a><span class="co"># 0.8344279</span></span>
<span id="cb388-2"><a href="reliability-and-validity.html#cb388-2" tabindex="-1"></a></span>
<span id="cb388-3"><a href="reliability-and-validity.html#cb388-3" tabindex="-1"></a><span class="co"># ICC (Single_fixed_raters) = ICC3 in psych output</span></span>
<span id="cb388-4"><a href="reliability-and-validity.html#cb388-4" tabindex="-1"></a><span class="fl">270.882</span> <span class="sc">/</span> (<span class="fl">270.882</span> <span class="sc">+</span> <span class="fl">47.557</span>) <span class="co">#</span></span></code></pre></div>
<pre><code>## [1] 0.8506559</code></pre>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="reliability-and-validity.html#cb390-1" tabindex="-1"></a><span class="co"># 0.85</span></span></code></pre></div>
</div>
<div id="explanation-of-iccs-in-the-psych-output" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Explanation of ICCs in the <code>psych</code> output<a href="reliability-and-validity.html#explanation-of-iccs-in-the-psych-output" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you want to know all the details, refer to <a href="https://d1wqtxts1xzle7.cloudfront.net/50483847/syarat_reliabilitas_icc-libre.pdf?1479841049=&amp;response-content-disposition=inline%3B+filename%3DIntraclass_Correlations_Uses_in_Assessin.pdf&amp;Expires=1740684631&amp;Signature=hHiFbcQD3PDVIyWDJ-bUhcm3WtsK19YhHm6FKtnafNdqsm9NhR6cr9lbCf~gVV5SYG1XlTwLlcfJkQ9Z-ahjmmNV893aWi5plo~yL4oZBEjrmFa9WCd7k6vzFTkri1Xbgfh~GyPARWXBtqABytovtL-RD1420Kw9qk150nw3-kUWcuvRiIc~r0y65XQaXf-V9mm~uXRFdUqec4Vs-Bwh~IrJfHWQASGgp8wZjzh2130MCP3-iaorxNn~79c~nm2f1aIl5WRqRXB6EIy8HlrNFpxNSt1pgTPZoZadEECM4qH395KLY5ijUnhoCDT9AmcOplPnFiC5t8dKW-n25ziofQ__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">Shrout and Fleiss (1979)</a>.
The help-function <code>?psych::ICC</code> containts a relatively good and much shorter explanation.
The variance formulae given in the help-file are probably somewhat confusing.
We try to stick to the notation of the book.</p>
<p>Let’s talk about the first three <strong>ICCs in the <code>psych</code> output</strong>:.</p>
<ul>
<li><p><strong>Single_raters_absolute ICC1:</strong>
According to the help file: “Each target is rated by a different
judge and the judges are selected at random.” So, variability due to raters
is implied and cannot be disentangled.
This is formally not our situation, since we have only two raters and
50 patients. But for this case, we do not care who measures, since we do not
model it, hence, we cannot know if there are systematic differences between
the raters. There might as well be 50 raters doing their thing, or just 2 as in our case.
This is the ICC we calculated above; called <span class="math inline">\(ICC_{consistency}\)</span>
in the book and based on the following model:</p>
<p><span class="math display">\[ Y_{ij} = \eta_i + \varepsilon_i \]</span>
where <span class="math inline">\(i \in {1,...,50}\)</span> is the patient and <span class="math inline">\(j \in {1,2}\)</span> is the <em>measurement</em>
(<span class="math inline">\(=50*2=100\)</span> rows in long format).
Note that we do not mention a rater here, since we do not care who took the
measurement. It is not part of the model. The ICC is then calculated as:
<span class="math display">\[ ICC_{consistency} = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2}\]</span>
whereas we could get the variance components from either the posterior in the Bayesian
setting or from the <code>lmer</code> output in the Frequentist setting.</p></li>
<li><p><strong>Single_random_raters ICC2:</strong>
ICC2 and ICC3 are based on the <strong>same</strong> statistical model. The only difference is
that ICC2 assumes that the (in our case) 2 raters are randomly selected from a larger pool of raters,
hence, the rater variability must be explicitely considered and yields a potentially smaller
value for the ICC. Compared to ICC1, we have repeated measurements from the same raters
in 50 patients. That’s why we can model their bias. One observation would not be enough.
The help file says: “A random sample of k judges rate each target.
The measure is one of absolute agreement in the ratings.”
A random sample of k (2 in our case) judges means that we cannot rule out the variability
due to raters (you get a variety of them and they biases are different).</p>
<p><span class="math display">\[ Y_{ij} = \eta_i + \beta_j + \varepsilon_i \]</span>
where <span class="math inline">\(i \in {1,...,50}\)</span> is the patient, <span class="math inline">\(j \in {1,2}\)</span> is the <strong>rater</strong>
(doing one measurement in each patient). The ICC is then calculated as:</p>
<p><span class="math display">\[ ICC_{agreement} = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 +\mathbf{\sigma_{rater}^2} +
\sigma_{\varepsilon}^2}\]</span></p></li>
<li><p><strong>Single_fixed_raters ICC3:</strong>
ICC3 is based on the <strong>same model as ICC2</strong>, but assumes that the raters are fixed.
This means that <strong>the raters are the same for all patients</strong> in the future study.
So, we have considered the rater variability in the model
(which was possible due to the repeated measurements from the same raters in 50 patients),
but do not care since Mary and Peter will be the people doing the future
measurements, not other therapists. If you fix a stochastic variable
(raters in this case), variance is zero. The help file says:
“A fixed set of k judges rate each target.
There is no generalization to a larger population of judges.”
The ICC is then calculated as:</p>
<p><span class="math display">\[ ICC_{agreement} = \frac{\sigma_{\eta}^2}{\sigma_{\eta}^2 + \sigma_{\varepsilon}^2}\]</span></p>
<p>ICC1 and ICC3 are <strong>not</strong> identical, since ICC1 does not consider the rater variability
in the model.</p></li>
</ul>
<p>If there is no systematic difference between raters, all 3 ICCs and the Pearson
correlation (r) are the same (see Figure 5.3 in the book).</p>
<p><span class="math inline">\(ICC_{consistency}\)</span> vs. <span class="math inline">\(ICC_{agreement}\)</span>:
The latter is used, when we need Peter and Mary to concur in their measurements.
Patients coming to Peters practice will get the same “diagnosis” (ROM-value)
from Mary. When there is systematic difference (line is shifted downwards in Figure 5.3),
this cannot be guaranteed.</p>
</div>
<div id="summary-peter-and-mary-with-and-without-bias" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Summary Peter and Mary, with and without bias<a href="reliability-and-validity.html#summary-peter-and-mary-with-and-without-bias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Below, we summarize the results for the ICCs (calculated with <code>psych</code>)
for the unbiased and biased case (Mary measures on average 5 degrees more than peter).</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="reliability-and-validity.html#cb391-1" tabindex="-1"></a><span class="fu">library</span>(pacman)</span>
<span id="cb391-2"><a href="reliability-and-validity.html#cb391-2" tabindex="-1"></a><span class="fu">p_load</span>(conflicted, tidyverse, flextable)</span>
<span id="cb391-3"><a href="reliability-and-validity.html#cb391-3" tabindex="-1"></a></span>
<span id="cb391-4"><a href="reliability-and-validity.html#cb391-4" tabindex="-1"></a><span class="co"># Ensure select() from dplyr is used</span></span>
<span id="cb391-5"><a href="reliability-and-validity.html#cb391-5" tabindex="-1"></a><span class="fu">conflicts_prefer</span>(dplyr<span class="sc">::</span>select)</span></code></pre></div>
<pre><code>## [conflicted] Removing existing preference.
## [conflicted] Will prefer dplyr::select over any other package.</code></pre>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="reliability-and-validity.html#cb393-1" tabindex="-1"></a><span class="co"># Unbiased ICC Calculation</span></span>
<span id="cb393-2"><a href="reliability-and-validity.html#cb393-2" tabindex="-1"></a>df_wide_unbiased <span class="ot">&lt;-</span> df_long <span class="sc">%&gt;%</span></span>
<span id="cb393-3"><a href="reliability-and-validity.html#cb393-3" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Rater, <span class="at">values_from =</span> ROM)</span>
<span id="cb393-4"><a href="reliability-and-validity.html#cb393-4" tabindex="-1"></a>df_wide_values_unbiased <span class="ot">&lt;-</span> df_wide_unbiased <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>ID)</span>
<span id="cb393-5"><a href="reliability-and-validity.html#cb393-5" tabindex="-1"></a>icc_results_unbiased <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">ICC</span>(df_wide_values_unbiased)</span></code></pre></div>
<pre><code>## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="reliability-and-validity.html#cb395-1" tabindex="-1"></a><span class="co"># Extract relevant ICC values</span></span>
<span id="cb395-2"><a href="reliability-and-validity.html#cb395-2" tabindex="-1"></a>icc_unbiased_df <span class="ot">&lt;-</span> icc_results_unbiased<span class="sc">$</span>results <span class="sc">%&gt;%</span></span>
<span id="cb395-3"><a href="reliability-and-validity.html#cb395-3" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(type, ICC) <span class="sc">%&gt;%</span></span>
<span id="cb395-4"><a href="reliability-and-validity.html#cb395-4" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">`</span><span class="at">Unbiased ICC</span><span class="st">`</span> <span class="ot">=</span> ICC)</span>
<span id="cb395-5"><a href="reliability-and-validity.html#cb395-5" tabindex="-1"></a></span>
<span id="cb395-6"><a href="reliability-and-validity.html#cb395-6" tabindex="-1"></a><span class="co"># Biased ICC Calculation</span></span>
<span id="cb395-7"><a href="reliability-and-validity.html#cb395-7" tabindex="-1"></a>df_wide_biased <span class="ot">&lt;-</span> df_long_bias <span class="sc">%&gt;%</span></span>
<span id="cb395-8"><a href="reliability-and-validity.html#cb395-8" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Rater, <span class="at">values_from =</span> ROM)</span>
<span id="cb395-9"><a href="reliability-and-validity.html#cb395-9" tabindex="-1"></a>df_wide_values_biased <span class="ot">&lt;-</span> df_wide_biased <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>ID)</span>
<span id="cb395-10"><a href="reliability-and-validity.html#cb395-10" tabindex="-1"></a>icc_results_biased <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">ICC</span>(df_wide_values_biased)</span>
<span id="cb395-11"><a href="reliability-and-validity.html#cb395-11" tabindex="-1"></a></span>
<span id="cb395-12"><a href="reliability-and-validity.html#cb395-12" tabindex="-1"></a><span class="co"># Extract relevant ICC values</span></span>
<span id="cb395-13"><a href="reliability-and-validity.html#cb395-13" tabindex="-1"></a>icc_biased_df <span class="ot">&lt;-</span> icc_results_biased<span class="sc">$</span>results <span class="sc">%&gt;%</span></span>
<span id="cb395-14"><a href="reliability-and-validity.html#cb395-14" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(type, ICC) <span class="sc">%&gt;%</span></span>
<span id="cb395-15"><a href="reliability-and-validity.html#cb395-15" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">`</span><span class="at">Biased ICC</span><span class="st">`</span> <span class="ot">=</span> ICC)</span>
<span id="cb395-16"><a href="reliability-and-validity.html#cb395-16" tabindex="-1"></a></span>
<span id="cb395-17"><a href="reliability-and-validity.html#cb395-17" tabindex="-1"></a>icc_merged_df <span class="ot">&lt;-</span> <span class="fu">left_join</span>(icc_unbiased_df, </span>
<span id="cb395-18"><a href="reliability-and-validity.html#cb395-18" tabindex="-1"></a>                           icc_biased_df, </span>
<span id="cb395-19"><a href="reliability-and-validity.html#cb395-19" tabindex="-1"></a>                           <span class="at">by =</span> <span class="st">&quot;type&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb395-20"><a href="reliability-and-validity.html#cb395-20" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span>
<span id="cb395-21"><a href="reliability-and-validity.html#cb395-21" tabindex="-1"></a></span>
<span id="cb395-22"><a href="reliability-and-validity.html#cb395-22" tabindex="-1"></a>ft <span class="ot">&lt;-</span> <span class="fu">flextable</span>(icc_merged_df) <span class="sc">%&gt;%</span></span>
<span id="cb395-23"><a href="reliability-and-validity.html#cb395-23" tabindex="-1"></a>  flextable<span class="sc">::</span><span class="fu">set_header_labels</span>(<span class="at">type =</span> <span class="st">&quot;ICC Type&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb395-24"><a href="reliability-and-validity.html#cb395-24" tabindex="-1"></a>  flextable<span class="sc">::</span><span class="fu">set_caption</span>(<span class="st">&quot;Intraclass Correlation Coefficients - Unbiased vs. Biased&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb395-25"><a href="reliability-and-validity.html#cb395-25" tabindex="-1"></a>  flextable<span class="sc">::</span><span class="fu">set_table_properties</span>(<span class="at">width =</span> .<span class="dv">5</span>, <span class="at">layout =</span> <span class="st">&quot;autofit&quot;</span>)</span>
<span id="cb395-26"><a href="reliability-and-validity.html#cb395-26" tabindex="-1"></a>ft</span></code></pre></div>
<div class="tabwid"><style>.cl-3be5ca8e{table-layout:auto;width:50%;}.cl-3be2280c{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-3be3b212{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-3be3b213{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-3be3c180{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3be3c1bc{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3be3c1bd{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3be3c1be{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3be3c1c6{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3be3c1c7{background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-3be5ca8e'>
<caption style="display:table-caption;margin:0pt;text-align:center;border-bottom: 0.00pt solid transparent;border-top: 0.00pt solid transparent;border-left: 0.00pt solid transparent;border-right: 0.00pt solid transparent;padding-top:3pt;padding-bottom:3pt;padding-left:3pt;padding-right:3pt;line-height: 1;background-color:transparent;"><span id="tab:unnamed-chunk-104">Table 5.1: </span><span>Intraclass Correlation Coefficients - Unbiased vs. Biased</span></caption>
<thead><tr style="overflow-wrap:break-word;"><th class="cl-3be3c180"><p class="cl-3be3b212"><span class="cl-3be2280c">ICC Type</span></p></th><th class="cl-3be3c1bc"><p class="cl-3be3b213"><span class="cl-3be2280c">Unbiased ICC</span></p></th><th class="cl-3be3c1bc"><p class="cl-3be3b213"><span class="cl-3be2280c">Biased ICC</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-3be3c1bd"><p class="cl-3be3b212"><span class="cl-3be2280c">ICC1</span></p></td><td class="cl-3be3c1be"><p class="cl-3be3b213"><span class="cl-3be2280c">0.8512574</span></p></td><td class="cl-3be3c1be"><p class="cl-3be3b213"><span class="cl-3be2280c">0.8328336</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-3be3c1bd"><p class="cl-3be3b212"><span class="cl-3be2280c">ICC2</span></p></td><td class="cl-3be3c1be"><p class="cl-3be3b213"><span class="cl-3be2280c">0.8512574</span></p></td><td class="cl-3be3c1be"><p class="cl-3be3b213"><span class="cl-3be2280c">0.8344281</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-3be3c1c6"><p class="cl-3be3b212"><span class="cl-3be2280c">ICC3</span></p></td><td class="cl-3be3c1c7"><p class="cl-3be3b213"><span class="cl-3be2280c">0.8512574</span></p></td><td class="cl-3be3c1c7"><p class="cl-3be3b213"><span class="cl-3be2280c">0.8506562</span></p></td></tr></tbody></table></div>
<ul>
<li><p>The left cloumn shows that the ICCs are identical for the unbiased case.
Specifically, ICC2 and ICC3 are based on the same model which explicitely
considers a potential bias between the raters. Since there is none,
the ICCs are the same.</p></li>
<li><p>In the biased case, there <em>is</em> as systematic difference between Mary and Peter.
ICC1 does not care about it and shows a somehwat lower value compared to
before (<span class="math inline">\(0.833\)</span>). The reason is because the agreement line is in a plot with
Mary on Y and Peter on X shifted upwards by 5 degrees.
If you would introduce a bias of 15 degrees, the ICC would
be even lower (<span class="math inline">\(ICC1 = 0.61\)</span>, <span class="math inline">\(ICC2 = 0.65\)</span> -&gt; verify exercise).
The unbiased columns would of course stay the same.</p></li>
<li><p>ICC2 now consideres the bias of 5 degrees. The model knows about the shift.
If we compare the variance components of ICC1 and ICC2, we see:</p></li>
</ul>
</div>
<div id="difference-between-correlation-and-icc" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Difference between correlation and ICC<a href="reliability-and-validity.html#difference-between-correlation-and-icc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we do not introduce a bias in the data, the correlation coefficient
is the same as the ICC (as seen above). On page 110, Figure 5.3, the authors show nicely
what the difference is between the correlation coefficient and the ICC. We note:</p>
<ul>
<li>The <span class="math inline">\(ICC_{agreement}\)</span> measures how tightly the two measurements are
clustered around the line of equality (<span class="math inline">\(y=x\)</span>)……..
……..</li>
</ul>
</div>
<div id="bad-news-about-the-icc" class="section level3 hasAnchor" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Bad news about the ICC?<a href="reliability-and-validity.html#bad-news-about-the-icc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>…</p>
</div>
<div id="standard-error-of-measurement-sem" class="section level3 hasAnchor" number="5.1.7">
<h3><span class="header-section-number">5.1.7</span> Standard Error of Measurement (SEM)<a href="reliability-and-validity.html#standard-error-of-measurement-sem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>…</p>
</div>
<div id="bland-altman-plot" class="section level3 hasAnchor" number="5.1.8">
<h3><span class="header-section-number">5.1.8</span> Bland-Altman Plot<a href="reliability-and-validity.html#bland-altman-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>…</p>
</div>
</div>
<div id="validity" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Validity<a href="reliability-and-validity.html#validity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>…</p>
</div>
<div id="todos" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> TODOS<a href="reliability-and-validity.html#todos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>mention missing values, missingness mechanisms -&gt; Methodenvertiefung</li>
<li>Logistic Regression, Poisson, -&gt; Methodenvertiefung</li>
<li>Exercise: Show by simulation what Gelman talks about with significant p values. So I scan the data
for significant p values and then simulate data with the same effect size and see how often
I get significant p values. Especially the next effect would be probably smaller,
especially, if one did p-hacking! Calculate a priori probability for replication (def?).</li>
<li>Chapter: Sample size calculations for multivariate regression, Proportions, ICCs, t.test</li>
<li>Chapter about Reliability, Validity and ICCs (incl. simulation of what an ICC of 0.9 or so means), but maybe reduced</li>
<li>Angenommen man hat ein masking eines Effekts und der Model fit ist aber gut (keine Voraussetzung verletzt),
ist diese Situation möglich?</li>
<li>What about papers? -&gt; eLearning</li>
<li>AIC, BIC, cross-validation, Model selection (best subset, leaps….), Variable selection</li>
<li>More on bias variance tradeoff, show for polynomial regression?</li>
<li>include eLearning tasks in script.</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-linear-regression.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-Reliability_Validity.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
